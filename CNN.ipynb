{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYb2Py1uCNEmpqjVThajWO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/russellw999/PyTorch-Tutorial-YouTube-Codemy/blob/master/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONrkbqVICCoA"
      },
      "outputs": [],
      "source": [
        "# Video 14 Convoluted neural Network - Import MNIST Images - Deep Learning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from io import IncrementalNewlineDecoder\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "%matplotlib inline\n"
      ],
      "metadata": {
        "id": "1yzEuxQrCTQ2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Images are 2 D but we need extra dimensions\n",
        "# Convert MNIS Image Files into a TENSOR OF 4-dimensions ( # of images, Height, Width, Color Channel)\n",
        "transform = transforms.ToTensor()\n"
      ],
      "metadata": {
        "id": "zfidFXOEDV5K"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Data\n",
        "train_data = datasets.MNIST(root='/cnn_data', train=True, download=True, transform=transform)"
      ],
      "metadata": {
        "id": "r7_PA3ijJl0x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fef9d22a-ebc0-489f-9f57-6767aa57f59b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:01<00:00, 5.26MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 154kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.46MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 6.32MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = datasets.MNIST(root='/cnn_data', train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "id": "O34jdZqhJ08i"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUinN4diKMbw",
        "outputId": "8fd0d1b5-eb06-4243-ea38-efcb217e0306"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: /cnn_data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORec0p6-KQ0w",
        "outputId": "33352f2f-ec8c-43ce-e32a-ff063ca15491"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 10000\n",
              "    Root location: /cnn_data\n",
              "    Split: Test\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# End of of Video 14 -\n",
        "#.  set up the CNN, Imported required libraries, created a transform to change the images to a 4 D tensor\n",
        "#   set up the training data downloaed and installed, set up the test data\n",
        "\n"
      ],
      "metadata": {
        "id": "vyheA5mxKYN8"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Video 15 Build the CNN\n",
        "\n",
        "# Create a small batch size for images...let's say 10\n",
        "train_loader = DataLoader(train_data, batch_size=1, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=1, shuffle=False)"
      ],
      "metadata": {
        "id": "ZacAe-0lKewO"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Our CNN Model\n",
        "# Describe convolutional layer and what it's doing ( 2 convolutional layers)\n",
        "# This is just an example the next video will build out the model\n",
        "\n",
        "#\n",
        "# conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=(3,3))\n",
        "# conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=(3,3))\n",
        "conv1 = nn.Conv2d(1, 6, 3, 1)\n",
        "conv2 = nn.Conv2d(6, 16, 3, 1)"
      ],
      "metadata": {
        "id": "4p5_sZjyVScE"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grab 1 MNIS record/image\n",
        "for i, (X_train, y_train) in enumerate(train_loader):\n",
        "    break"
      ],
      "metadata": {
        "id": "Kd76C9YHW54S"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ay6mG0JTXVU_",
        "outputId": "4d7e0e41-52d4-4224-ab49-c9564e753da5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.1294, 0.9098, 0.1882, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.4941, 0.9961, 0.8980, 0.0471,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.4941, 0.9961, 0.9961, 0.0627,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.2392, 0.9961, 0.9961, 0.1333,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0196, 0.7294, 0.9961, 0.4902,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6392, 0.9961, 0.5020,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6392, 0.9961, 0.9137,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6392, 0.9961, 0.9137,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6392, 0.9961, 0.9137,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6392, 0.9961, 0.8196,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6392, 0.9961, 0.4902,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6392, 0.9961, 0.4902,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0431, 0.8784, 0.9961, 0.4902,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0667, 0.9961, 0.9961, 0.1412,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.4784, 0.9961, 0.8039, 0.0314,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.7804, 1.0000, 0.6353, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.9176, 0.9961, 0.6353, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.9176, 0.9961, 0.6353, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.9176, 0.9961, 0.6353, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.3725, 0.7255, 0.3647, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-mkxlJ2XuV8",
        "outputId": "299cc215-03b9-4de0-ed62-09799fe9df41"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = X_train.view(1,1,28,28)  # change to 4 dimensional.  1 batch of 1 image of 28 x 28\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkK49FzaXz7A",
        "outputId": "10a86d98-32f4-4cd4-f3ec-b2eb8c0f804b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.1294, 0.9098, 0.1882, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.4941, 0.9961, 0.8980, 0.0471,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.4941, 0.9961, 0.9961, 0.0627,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.2392, 0.9961, 0.9961, 0.1333,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0196, 0.7294, 0.9961, 0.4902,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6392, 0.9961, 0.5020,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6392, 0.9961, 0.9137,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6392, 0.9961, 0.9137,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6392, 0.9961, 0.9137,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6392, 0.9961, 0.8196,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6392, 0.9961, 0.4902,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6392, 0.9961, 0.4902,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0431, 0.8784, 0.9961, 0.4902,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0667, 0.9961, 0.9961, 0.1412,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.4784, 0.9961, 0.8039, 0.0314,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.7804, 1.0000, 0.6353, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.9176, 0.9961, 0.6353, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.9176, 0.9961, 0.6353, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.9176, 0.9961, 0.6353, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.3725, 0.7255, 0.3647, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform our first convolution\n",
        "x = F.relu(conv1(x)) # Rectified Linear Unit for our activation function\n"
      ],
      "metadata": {
        "id": "ARoU7qHthHVR"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 single image, 6 is the filters we asked for, 26x26 is the image ( not 28x28 as the padding was removed)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sY1dFfqRh1Ot",
        "outputId": "0a5c77b8-067d-40cd-e12c-57c196796411"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 6, 26, 26])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pass thru the pooling layer\n",
        "\n",
        "x = F.max_pool2d(x, 2, 2) # kernal of 2 and stride of 2"
      ],
      "metadata": {
        "id": "atkC2m01i8dA"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape  # 26 / 2 = 13  (stride was set to 2 in previous step)"
      ],
      "metadata": {
        "id": "YiC7XqfcjZT8",
        "outputId": "82121af9-30a5-4d7a-cef8-bf2cedf14370",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 6, 13, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Do our second convolutional layer.  (same x as its all linear one after the otehr)\n",
        "x = F.relu(conv2(x))  #. conv2 is ( 6, 16, 3, 1)"
      ],
      "metadata": {
        "id": "rU00ndIJjoUM"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape   # Again we did not set padding so we lose 2 px around the outside of image"
      ],
      "metadata": {
        "id": "AzHbJubWj_Qg",
        "outputId": "0f23985e-399f-4796-fb02-32129247e341",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 16, 11, 11])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pooling layer\n",
        "x = F.max_pool2d(x, 2, 2)"
      ],
      "metadata": {
        "id": "8Db_0Pz3kPEA"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape # 11/2 = 5.5 but we have to rounddown , because you can't invent data to round up"
      ],
      "metadata": {
        "id": "pdaupdqBkWlJ",
        "outputId": "35e4a75c-57e3-4304-d390-ee42f566afac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 16, 5, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# End of Video 15 - we have taken an image and passed it through 2 convolutions and poolings"
      ],
      "metadata": {
        "id": "i8lurPMkki4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Video 17 Builld a Model"
      ],
      "metadata": {
        "id": "GrEjwV_f6er1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Class\n",
        "class ConvolutionalNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(1,6,3,1)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 3,1)\n",
        "    # Fully Connected Layer\n",
        "    self.fc1 = nn.Linear(5*5*16, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, X):\n",
        "    X = F.relu(self.conv1(X))\n",
        "    X = F.max_pool2d(X, 2,2)   # 2x2 kernal and stride 2\n",
        "    # Second Pass\n",
        "    X = F.relu(self.conv2(X))\n",
        "    X = F.max_pool2d(X, 2,2)   # 2x2 kernal and stride 2\n",
        "\n",
        "    # Re-View to flatten out\n",
        "    X = X.view(-1, 16*5*5)   # -1 one so that we can vary the batch size\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    X = F.relu(self.fc1(X))\n",
        "    X = F.relu(self.fc2(X))\n",
        "    X = self.fc3(X)\n",
        "\n",
        "    return F.log_softmax(X, dim=1)\n"
      ],
      "metadata": {
        "id": "sb1tXejE66JX"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an Instance of our Model\n",
        "torch.manual_seed(41)\n",
        "model = ConvolutionalNetwork()\n",
        "\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vn3bMaqu-_wc",
        "outputId": "23704dec-4693-4bbd-d390-c271ebc4eb52"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvolutionalNetwork(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss Function Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # Smaller the Learning Rate, the longer it takes to train"
      ],
      "metadata": {
        "id": "vehZDXL6_k8i"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# End of Video 16 Create model\n",
        "# Start of Video 17 Train Data"
      ],
      "metadata": {
        "id": "bPZVGxT8ABtj"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "# Create variables to Track Things\n",
        "epochs = 5\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_correct = []\n",
        "test_correct = []\n",
        "\n",
        "#   For Loop of Epochs\n",
        "for i in range(epochs):\n",
        "  trn_corr = 0\n",
        "  tst_corr = 0\n",
        "\n",
        "  # Train\n",
        "  for b,(X_train, y_train) in enumerate(train_loader):\n",
        "      b+=1\n",
        "      # Apply our model\n",
        "      y_pred = model(X_train)  # get the predicteds values from the training set, Not flattened 2D\n",
        "      loss = criterion(y_pred, y_train) # how off are we? Compare the predictions to correct answers in Y_train\n",
        "\n",
        "      predicted = torch.max(y_pred.data,1)[1] # add up the number of correct predictions. Indexed off the first point\n",
        "      batch_correct = (predicted == y_train).sum() # how many we got correct from this batch. True = 1, False = 0, sum those up\n",
        "      trn_corr += batch_correct # add up the number of correct predictions\n",
        "\n",
        "      # Update our parameters\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "\n",
        "      # Print out some results\n",
        "      if b%600 == 0:\n",
        "        print(f'Epoch: {i}  Batch: {b}  Loss: {loss.item()}')\n",
        "\n",
        "  train_losses.append(loss)\n",
        "  train_correct.append(trn_corr)\n",
        "\n",
        "  # Test\n",
        "  with torch.no_grad():     # No gradient so we don't update our weights abd biases with test\n",
        "      for b, (X_test, y_test) in enumerate(test_loader):\n",
        "        y_val = model(X_test)\n",
        "        predicted = torch.max(y_val.data, 1)[1] # Adding up correct predictions\n",
        "        tst_corr += (predicted == y_test).sum()\n",
        "\n",
        "  loss = criterion(y_val, y_test)\n",
        "  test_losses.append(loss)\n",
        "  test_correct.append(tst_corr)\n",
        "\n",
        "\n",
        "\n",
        "current_time = time.time()\n",
        "elapsed_time = current_time - start_time\n",
        "print(f'Training Took: {elapsed_time/60}minutes!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hdJfwe4AZ6k",
        "outputId": "0b84e3a6-3409-4c6e-838b-7b13951d9db3"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0  Batch: 600  Loss: 0.08787637948989868\n",
            "Epoch: 0  Batch: 1200  Loss: 2.5110254287719727\n",
            "Epoch: 0  Batch: 1800  Loss: 0.14741575717926025\n",
            "Epoch: 0  Batch: 2400  Loss: 2.3756425380706787\n",
            "Epoch: 0  Batch: 3000  Loss: 0.0034033493138849735\n",
            "Epoch: 0  Batch: 3600  Loss: 0.060373492538928986\n",
            "Epoch: 0  Batch: 4200  Loss: 0.0048146978951990604\n",
            "Epoch: 0  Batch: 4800  Loss: 0.020903753116726875\n",
            "Epoch: 0  Batch: 5400  Loss: 0.0005940818227827549\n",
            "Epoch: 0  Batch: 6000  Loss: 0.0009480987209826708\n",
            "Epoch: 0  Batch: 6600  Loss: 4.2676016164477915e-05\n",
            "Epoch: 0  Batch: 7200  Loss: 0.002409889828413725\n",
            "Epoch: 0  Batch: 7800  Loss: 1.811964830267243e-05\n",
            "Epoch: 0  Batch: 8400  Loss: 0.00024172721896320581\n",
            "Epoch: 0  Batch: 9000  Loss: 0.0003297977091278881\n",
            "Epoch: 0  Batch: 9600  Loss: 0.0015156697481870651\n",
            "Epoch: 0  Batch: 10200  Loss: 0.002953574061393738\n",
            "Epoch: 0  Batch: 10800  Loss: 0.002577556297183037\n",
            "Epoch: 0  Batch: 11400  Loss: 0.0009893052047118545\n",
            "Epoch: 0  Batch: 12000  Loss: 0.00021479207498487085\n",
            "Epoch: 0  Batch: 12600  Loss: 0.3600896894931793\n",
            "Epoch: 0  Batch: 13200  Loss: 5.817244164063595e-05\n",
            "Epoch: 0  Batch: 13800  Loss: 0.135885089635849\n",
            "Epoch: 0  Batch: 14400  Loss: 5.125986263010418e-06\n",
            "Epoch: 0  Batch: 15000  Loss: 0.016545584425330162\n",
            "Epoch: 0  Batch: 15600  Loss: 3.194758028257638e-05\n",
            "Epoch: 0  Batch: 16200  Loss: 2.622600959512056e-06\n",
            "Epoch: 0  Batch: 16800  Loss: 0.06772375851869583\n",
            "Epoch: 0  Batch: 17400  Loss: 0.66081702709198\n",
            "Epoch: 0  Batch: 18000  Loss: 0.0008709213580004871\n",
            "Epoch: 0  Batch: 18600  Loss: 1.549708758830093e-05\n",
            "Epoch: 0  Batch: 19200  Loss: 0.00026306029758416116\n",
            "Epoch: 0  Batch: 19800  Loss: 0.02193254791200161\n",
            "Epoch: 0  Batch: 20400  Loss: 0.0005548844928853214\n",
            "Epoch: 0  Batch: 21000  Loss: 0.8111323714256287\n",
            "Epoch: 0  Batch: 21600  Loss: 4.6132929128361866e-05\n",
            "Epoch: 0  Batch: 22200  Loss: 0.5408194661140442\n",
            "Epoch: 0  Batch: 22800  Loss: 0.007523180451244116\n",
            "Epoch: 0  Batch: 23400  Loss: 1.1920928244535389e-07\n",
            "Epoch: 0  Batch: 24000  Loss: 0.0006932000978849828\n",
            "Epoch: 0  Batch: 24600  Loss: 0.002448301063850522\n",
            "Epoch: 0  Batch: 25200  Loss: 0.021474698558449745\n",
            "Epoch: 0  Batch: 25800  Loss: 8.654219709569588e-05\n",
            "Epoch: 0  Batch: 26400  Loss: 1.4755313396453857\n",
            "Epoch: 0  Batch: 27000  Loss: 9.762764238985255e-05\n",
            "Epoch: 0  Batch: 27600  Loss: 0.0\n",
            "Epoch: 0  Batch: 28200  Loss: 3.576278118089249e-07\n",
            "Epoch: 0  Batch: 28800  Loss: 2.0265373677830212e-05\n",
            "Epoch: 0  Batch: 29400  Loss: 0.00022301571152638644\n",
            "Epoch: 0  Batch: 30000  Loss: 2.372236667724792e-05\n",
            "Epoch: 0  Batch: 30600  Loss: 0.026774199679493904\n",
            "Epoch: 0  Batch: 31200  Loss: 0.022593233734369278\n",
            "Epoch: 0  Batch: 31800  Loss: 0.0\n",
            "Epoch: 0  Batch: 32400  Loss: 0.0001501924270996824\n",
            "Epoch: 0  Batch: 33000  Loss: 0.0008073169738054276\n",
            "Epoch: 0  Batch: 33600  Loss: 0.0014788892585784197\n",
            "Epoch: 0  Batch: 34200  Loss: 0.00015341058315243572\n",
            "Epoch: 0  Batch: 34800  Loss: 2.5033637939486653e-05\n",
            "Epoch: 0  Batch: 35400  Loss: 0.0\n",
            "Epoch: 0  Batch: 36000  Loss: 0.18889440596103668\n",
            "Epoch: 0  Batch: 36600  Loss: 0.42173802852630615\n",
            "Epoch: 0  Batch: 37200  Loss: 0.0010543270036578178\n",
            "Epoch: 0  Batch: 37800  Loss: 0.0005399914807640016\n",
            "Epoch: 0  Batch: 38400  Loss: 7.629365427419543e-06\n",
            "Epoch: 0  Batch: 39000  Loss: 0.0005947966128587723\n",
            "Epoch: 0  Batch: 39600  Loss: 1.1920922133867862e-06\n",
            "Epoch: 0  Batch: 40200  Loss: 0.0029273061081767082\n",
            "Epoch: 0  Batch: 40800  Loss: 0.04375215247273445\n",
            "Epoch: 0  Batch: 41400  Loss: 7.748573807475623e-06\n",
            "Epoch: 0  Batch: 42000  Loss: 0.00018857131362892687\n",
            "Epoch: 0  Batch: 42600  Loss: 2.7656173188006505e-05\n",
            "Epoch: 0  Batch: 43200  Loss: 1.311301275563892e-06\n",
            "Epoch: 0  Batch: 43800  Loss: 2.0265558760002023e-06\n",
            "Epoch: 0  Batch: 44400  Loss: 0.00702210608869791\n",
            "Epoch: 0  Batch: 45000  Loss: 8.344646857949556e-07\n",
            "Epoch: 0  Batch: 45600  Loss: 0.0062559256330132484\n",
            "Epoch: 0  Batch: 46200  Loss: 0.262514591217041\n",
            "Epoch: 0  Batch: 46800  Loss: 2.062299427052494e-05\n",
            "Epoch: 0  Batch: 47400  Loss: 0.04923665523529053\n",
            "Epoch: 0  Batch: 48000  Loss: 2.264974000354414e-06\n",
            "Epoch: 0  Batch: 48600  Loss: 0.0010926711838692427\n",
            "Epoch: 0  Batch: 49200  Loss: 0.031203782185912132\n",
            "Epoch: 0  Batch: 49800  Loss: 5.960462772236497e-07\n",
            "Epoch: 0  Batch: 50400  Loss: 0.039657413959503174\n",
            "Epoch: 0  Batch: 51000  Loss: 0.0\n",
            "Epoch: 0  Batch: 51600  Loss: 3.576278118089249e-07\n",
            "Epoch: 0  Batch: 52200  Loss: 0.005784912966191769\n",
            "Epoch: 0  Batch: 52800  Loss: 0.0015570909017696977\n",
            "Epoch: 0  Batch: 53400  Loss: 0.0007151191821321845\n",
            "Epoch: 0  Batch: 54000  Loss: 3.3378044463461265e-05\n",
            "Epoch: 0  Batch: 54600  Loss: 0.08801110088825226\n",
            "Epoch: 0  Batch: 55200  Loss: 0.0001161031104857102\n",
            "Epoch: 0  Batch: 55800  Loss: 0.0\n",
            "Epoch: 0  Batch: 56400  Loss: 1.0629326105117798\n",
            "Epoch: 0  Batch: 57000  Loss: 0.000675807474181056\n",
            "Epoch: 0  Batch: 57600  Loss: 0.0\n",
            "Epoch: 0  Batch: 58200  Loss: 0.0198720283806324\n",
            "Epoch: 0  Batch: 58800  Loss: 0.0014541300479322672\n",
            "Epoch: 0  Batch: 59400  Loss: 5.483612312673358e-06\n",
            "Epoch: 0  Batch: 60000  Loss: 5.435795901576057e-05\n",
            "Epoch: 1  Batch: 600  Loss: 0.00021884430316276848\n",
            "Epoch: 1  Batch: 1200  Loss: 5.960462772236497e-07\n",
            "Epoch: 1  Batch: 1800  Loss: 0.029333408921957016\n",
            "Epoch: 1  Batch: 2400  Loss: 0.0002441108226776123\n",
            "Epoch: 1  Batch: 3000  Loss: 0.00048744716332294047\n",
            "Epoch: 1  Batch: 3600  Loss: 0.00029476112104021013\n",
            "Epoch: 1  Batch: 4200  Loss: 0.008642295375466347\n",
            "Epoch: 1  Batch: 4800  Loss: 0.0\n",
            "Epoch: 1  Batch: 5400  Loss: 0.036424294114112854\n",
            "Epoch: 1  Batch: 6000  Loss: 0.00015877417172305286\n",
            "Epoch: 1  Batch: 6600  Loss: 0.0\n",
            "Epoch: 1  Batch: 7200  Loss: 2.3841855067985307e-07\n",
            "Epoch: 1  Batch: 7800  Loss: 0.0\n",
            "Epoch: 1  Batch: 8400  Loss: 0.006627128459513187\n",
            "Epoch: 1  Batch: 9000  Loss: 2.6940935640595853e-05\n",
            "Epoch: 1  Batch: 9600  Loss: 0.0\n",
            "Epoch: 1  Batch: 10200  Loss: 9.202533692587167e-05\n",
            "Epoch: 1  Batch: 10800  Loss: 5.602820692729438e-06\n",
            "Epoch: 1  Batch: 11400  Loss: 2.0265558760002023e-06\n",
            "Epoch: 1  Batch: 12000  Loss: 4.768370445162873e-07\n",
            "Epoch: 1  Batch: 12600  Loss: 1.9073468138230965e-06\n",
            "Epoch: 1  Batch: 13200  Loss: 3.3001279830932617\n",
            "Epoch: 1  Batch: 13800  Loss: 6.079655122448457e-06\n",
            "Epoch: 1  Batch: 14400  Loss: 0.0004576589271891862\n",
            "Epoch: 1  Batch: 15000  Loss: 2.5629668016335927e-05\n",
            "Epoch: 1  Batch: 15600  Loss: 1.2397689715726301e-05\n",
            "Epoch: 1  Batch: 16200  Loss: 1.1920928244535389e-07\n",
            "Epoch: 1  Batch: 16800  Loss: 1.0132738680113107e-05\n",
            "Epoch: 1  Batch: 17400  Loss: 0.01692904531955719\n",
            "Epoch: 1  Batch: 18000  Loss: 1.1920928244535389e-07\n",
            "Epoch: 1  Batch: 18600  Loss: 6.079655122448457e-06\n",
            "Epoch: 1  Batch: 19200  Loss: 3.4927710657939315e-05\n",
            "Epoch: 1  Batch: 19800  Loss: 0.00910853873938322\n",
            "Epoch: 1  Batch: 20400  Loss: 0.0022144813556224108\n",
            "Epoch: 1  Batch: 21000  Loss: 0.00034624303225427866\n",
            "Epoch: 1  Batch: 21600  Loss: 4.529942543740617e-06\n",
            "Epoch: 1  Batch: 22200  Loss: 0.00739704817533493\n",
            "Epoch: 1  Batch: 22800  Loss: 2.622600959512056e-06\n",
            "Epoch: 1  Batch: 23400  Loss: 3.1470757676288486e-05\n",
            "Epoch: 1  Batch: 24000  Loss: 1.4305104514278355e-06\n",
            "Epoch: 1  Batch: 24600  Loss: 0.0002299282787134871\n",
            "Epoch: 1  Batch: 25200  Loss: 0.0\n",
            "Epoch: 1  Batch: 25800  Loss: 1.1280848979949951\n",
            "Epoch: 1  Batch: 26400  Loss: 2.9801878554280847e-05\n",
            "Epoch: 1  Batch: 27000  Loss: 0.00019107422849629074\n",
            "Epoch: 1  Batch: 27600  Loss: 3.576278118089249e-07\n",
            "Epoch: 1  Batch: 28200  Loss: 0.0003400462737772614\n",
            "Epoch: 1  Batch: 28800  Loss: 0.0\n",
            "Epoch: 1  Batch: 29400  Loss: 0.014992416836321354\n",
            "Epoch: 1  Batch: 30000  Loss: 1.168244216387393e-05\n",
            "Epoch: 1  Batch: 30600  Loss: 0.0\n",
            "Epoch: 1  Batch: 31200  Loss: 0.0001358893496217206\n",
            "Epoch: 1  Batch: 31800  Loss: 0.0\n",
            "Epoch: 1  Batch: 32400  Loss: 0.0\n",
            "Epoch: 1  Batch: 33000  Loss: 0.00943499244749546\n",
            "Epoch: 1  Batch: 33600  Loss: 0.0\n",
            "Epoch: 1  Batch: 34200  Loss: 8.618460560683161e-05\n",
            "Epoch: 1  Batch: 34800  Loss: 0.0018717404454946518\n",
            "Epoch: 1  Batch: 35400  Loss: 1.0728830375228426e-06\n",
            "Epoch: 1  Batch: 36000  Loss: 8.237022848334163e-05\n",
            "Epoch: 1  Batch: 36600  Loss: 0.0\n",
            "Epoch: 1  Batch: 37200  Loss: 1.1920928244535389e-07\n",
            "Epoch: 1  Batch: 37800  Loss: 0.0\n",
            "Epoch: 1  Batch: 38400  Loss: 0.023286443203687668\n",
            "Epoch: 1  Batch: 39000  Loss: 0.004806156270205975\n",
            "Epoch: 1  Batch: 39600  Loss: 3.3378546504536644e-06\n",
            "Epoch: 1  Batch: 40200  Loss: 1.7881377516459906e-06\n",
            "Epoch: 1  Batch: 40800  Loss: 0.0\n",
            "Epoch: 1  Batch: 41400  Loss: 0.0009363081189803779\n",
            "Epoch: 1  Batch: 42000  Loss: 0.00029059001826681197\n",
            "Epoch: 1  Batch: 42600  Loss: 3.099436753473128e-06\n",
            "Epoch: 1  Batch: 43200  Loss: 0.0\n",
            "Epoch: 1  Batch: 43800  Loss: 5.960462772236497e-07\n",
            "Epoch: 1  Batch: 44400  Loss: 0.0\n",
            "Epoch: 1  Batch: 45000  Loss: 0.049165502190589905\n",
            "Epoch: 1  Batch: 45600  Loss: 0.0\n",
            "Epoch: 1  Batch: 46200  Loss: 0.0\n",
            "Epoch: 1  Batch: 46800  Loss: 0.0\n",
            "Epoch: 1  Batch: 47400  Loss: 0.0\n",
            "Epoch: 1  Batch: 48000  Loss: 4.768370445162873e-07\n",
            "Epoch: 1  Batch: 48600  Loss: 2.0265558760002023e-06\n",
            "Epoch: 1  Batch: 49200  Loss: 2.264974000354414e-06\n",
            "Epoch: 1  Batch: 49800  Loss: 2.3841855067985307e-07\n",
            "Epoch: 1  Batch: 50400  Loss: 2.3841855067985307e-07\n",
            "Epoch: 1  Batch: 51000  Loss: 0.0\n",
            "Epoch: 1  Batch: 51600  Loss: 3.576278118089249e-07\n",
            "Epoch: 1  Batch: 52200  Loss: 1.1920928244535389e-07\n",
            "Epoch: 1  Batch: 52800  Loss: 0.0024758896324783564\n",
            "Epoch: 1  Batch: 53400  Loss: 2.396077979938127e-05\n",
            "Epoch: 1  Batch: 54000  Loss: 1.1920928244535389e-07\n",
            "Epoch: 1  Batch: 54600  Loss: 2.312633478140924e-05\n",
            "Epoch: 1  Batch: 55200  Loss: 0.0\n",
            "Epoch: 1  Batch: 55800  Loss: 1.1444026313256472e-05\n",
            "Epoch: 1  Batch: 56400  Loss: 0.6434429883956909\n",
            "Epoch: 1  Batch: 57000  Loss: 0.03101889044046402\n",
            "Epoch: 1  Batch: 57600  Loss: 0.0\n",
            "Epoch: 1  Batch: 58200  Loss: 0.006275709252804518\n",
            "Epoch: 1  Batch: 58800  Loss: 0.0\n",
            "Epoch: 1  Batch: 59400  Loss: 0.00014494798961095512\n",
            "Epoch: 1  Batch: 60000  Loss: 0.0046953423880040646\n",
            "Epoch: 2  Batch: 600  Loss: 0.0001867835089797154\n",
            "Epoch: 2  Batch: 1200  Loss: 0.0003093002596870065\n",
            "Epoch: 2  Batch: 1800  Loss: 0.0002526917669456452\n",
            "Epoch: 2  Batch: 2400  Loss: 0.00011002412065863609\n",
            "Epoch: 2  Batch: 3000  Loss: 0.0\n",
            "Epoch: 2  Batch: 3600  Loss: 2.3841855067985307e-07\n",
            "Epoch: 2  Batch: 4200  Loss: 0.0\n",
            "Epoch: 2  Batch: 4800  Loss: 8.22540732769994e-06\n",
            "Epoch: 2  Batch: 5400  Loss: 7.629365427419543e-06\n",
            "Epoch: 2  Batch: 6000  Loss: 1.4305104514278355e-06\n",
            "Epoch: 2  Batch: 6600  Loss: 0.00017033556650858372\n",
            "Epoch: 2  Batch: 7200  Loss: 8.618460560683161e-05\n",
            "Epoch: 2  Batch: 7800  Loss: 2.622600959512056e-06\n",
            "Epoch: 2  Batch: 8400  Loss: 0.0\n",
            "Epoch: 2  Batch: 9000  Loss: 4.9232225137529895e-05\n",
            "Epoch: 2  Batch: 9600  Loss: 0.0\n",
            "Epoch: 2  Batch: 10200  Loss: 1.1941378116607666\n",
            "Epoch: 2  Batch: 10800  Loss: 0.0\n",
            "Epoch: 2  Batch: 11400  Loss: 0.0\n",
            "Epoch: 2  Batch: 12000  Loss: 0.0\n",
            "Epoch: 2  Batch: 12600  Loss: 6.151010165922344e-05\n",
            "Epoch: 2  Batch: 13200  Loss: 0.9266853332519531\n",
            "Epoch: 2  Batch: 13800  Loss: 0.0009110590908676386\n",
            "Epoch: 2  Batch: 14400  Loss: 1.1920922133867862e-06\n",
            "Epoch: 2  Batch: 15000  Loss: 0.0\n",
            "Epoch: 2  Batch: 15600  Loss: 5.61460001335945e-05\n",
            "Epoch: 2  Batch: 16200  Loss: 0.003338004695251584\n",
            "Epoch: 2  Batch: 16800  Loss: 8.344646857949556e-07\n",
            "Epoch: 2  Batch: 17400  Loss: 0.0\n",
            "Epoch: 2  Batch: 18000  Loss: 0.0\n",
            "Epoch: 2  Batch: 18600  Loss: 2.3841855067985307e-07\n",
            "Epoch: 2  Batch: 19200  Loss: 0.0018079616129398346\n",
            "Epoch: 2  Batch: 19800  Loss: 1.364565372467041\n",
            "Epoch: 2  Batch: 20400  Loss: 0.0\n",
            "Epoch: 2  Batch: 21000  Loss: 0.0\n",
            "Epoch: 2  Batch: 21600  Loss: 2.3841855067985307e-07\n",
            "Epoch: 2  Batch: 22200  Loss: 0.0\n",
            "Epoch: 2  Batch: 22800  Loss: 0.0\n",
            "Epoch: 2  Batch: 23400  Loss: 0.13269264996051788\n",
            "Epoch: 2  Batch: 24000  Loss: 2.3841855067985307e-07\n",
            "Epoch: 2  Batch: 24600  Loss: 8.702239938429557e-06\n",
            "Epoch: 2  Batch: 25200  Loss: 0.0\n",
            "Epoch: 2  Batch: 25800  Loss: 0.0319790318608284\n",
            "Epoch: 2  Batch: 26400  Loss: 3.4570634852570947e-06\n",
            "Epoch: 2  Batch: 27000  Loss: 2.3841855067985307e-07\n",
            "Epoch: 2  Batch: 27600  Loss: 5.411955135059543e-05\n",
            "Epoch: 2  Batch: 28200  Loss: 0.0\n",
            "Epoch: 2  Batch: 28800  Loss: 0.004482341464608908\n",
            "Epoch: 2  Batch: 29400  Loss: 0.0\n",
            "Epoch: 2  Batch: 30000  Loss: 2.2889699935913086\n",
            "Epoch: 2  Batch: 30600  Loss: 0.006374858319759369\n",
            "Epoch: 2  Batch: 31200  Loss: 1.823885577323381e-05\n",
            "Epoch: 2  Batch: 31800  Loss: 0.0\n",
            "Epoch: 2  Batch: 32400  Loss: 0.0\n",
            "Epoch: 2  Batch: 33000  Loss: 0.0005837167263962328\n",
            "Epoch: 2  Batch: 33600  Loss: 1.8715683836489916e-05\n",
            "Epoch: 2  Batch: 34200  Loss: 0.0009977606823667884\n",
            "Epoch: 2  Batch: 34800  Loss: 7.748573807475623e-06\n",
            "Epoch: 2  Batch: 35400  Loss: 0.00015484087634831667\n",
            "Epoch: 2  Batch: 36000  Loss: 1.1920922133867862e-06\n",
            "Epoch: 2  Batch: 36600  Loss: 0.002664113650098443\n",
            "Epoch: 2  Batch: 37200  Loss: 6.675497570540756e-05\n",
            "Epoch: 2  Batch: 37800  Loss: 0.0\n",
            "Epoch: 2  Batch: 38400  Loss: 0.011508270166814327\n",
            "Epoch: 2  Batch: 39000  Loss: 0.0\n",
            "Epoch: 2  Batch: 39600  Loss: 0.0\n",
            "Epoch: 2  Batch: 40200  Loss: 0.0\n",
            "Epoch: 2  Batch: 40800  Loss: 3.576278118089249e-07\n",
            "Epoch: 2  Batch: 41400  Loss: 0.0\n",
            "Epoch: 2  Batch: 42000  Loss: 0.00010787858627736568\n",
            "Epoch: 2  Batch: 42600  Loss: 2.5912914276123047\n",
            "Epoch: 2  Batch: 43200  Loss: 0.0\n",
            "Epoch: 2  Batch: 43800  Loss: 1.2993727978027891e-05\n",
            "Epoch: 2  Batch: 44400  Loss: 0.7015290856361389\n",
            "Epoch: 2  Batch: 45000  Loss: 2.002696055569686e-05\n",
            "Epoch: 2  Batch: 45600  Loss: 0.0\n",
            "Epoch: 2  Batch: 46200  Loss: 0.007510283961892128\n",
            "Epoch: 2  Batch: 46800  Loss: 1.1920928244535389e-07\n",
            "Epoch: 2  Batch: 47400  Loss: 4.529942543740617e-06\n",
            "Epoch: 2  Batch: 48000  Loss: 0.0\n",
            "Epoch: 2  Batch: 48600  Loss: 0.0\n",
            "Epoch: 2  Batch: 49200  Loss: 5.245195097813848e-06\n",
            "Epoch: 2  Batch: 49800  Loss: 6.318072337307967e-06\n",
            "Epoch: 2  Batch: 50400  Loss: 0.0\n",
            "Epoch: 2  Batch: 51000  Loss: 0.0\n",
            "Epoch: 2  Batch: 51600  Loss: 1.1920928244535389e-07\n",
            "Epoch: 2  Batch: 52200  Loss: 0.0\n",
            "Epoch: 2  Batch: 52800  Loss: 5.638440416078083e-05\n",
            "Epoch: 2  Batch: 53400  Loss: 0.0\n",
            "Epoch: 2  Batch: 54000  Loss: 1.545701026916504\n",
            "Epoch: 2  Batch: 54600  Loss: 0.0\n",
            "Epoch: 2  Batch: 55200  Loss: 0.0009538153535686433\n",
            "Epoch: 2  Batch: 55800  Loss: 0.27190709114074707\n",
            "Epoch: 2  Batch: 56400  Loss: 0.0\n",
            "Epoch: 2  Batch: 57000  Loss: 0.0\n",
            "Epoch: 2  Batch: 57600  Loss: 0.0\n",
            "Epoch: 2  Batch: 58200  Loss: 0.003473916556686163\n",
            "Epoch: 2  Batch: 58800  Loss: 2.6225699912174605e-05\n",
            "Epoch: 2  Batch: 59400  Loss: 0.0013468727702274919\n",
            "Epoch: 2  Batch: 60000  Loss: 0.0015048381173983216\n",
            "Epoch: 3  Batch: 600  Loss: 0.0\n",
            "Epoch: 3  Batch: 1200  Loss: 0.0006790239713154733\n",
            "Epoch: 3  Batch: 1800  Loss: 0.0\n",
            "Epoch: 3  Batch: 2400  Loss: 0.0\n",
            "Epoch: 3  Batch: 3000  Loss: 0.0\n",
            "Epoch: 3  Batch: 3600  Loss: 0.0\n",
            "Epoch: 3  Batch: 4200  Loss: 2.3841855067985307e-07\n",
            "Epoch: 3  Batch: 4800  Loss: 6.83045873302035e-05\n",
            "Epoch: 3  Batch: 5400  Loss: 3.576278118089249e-07\n",
            "Epoch: 3  Batch: 6000  Loss: 2.5033637939486653e-05\n",
            "Epoch: 3  Batch: 6600  Loss: 4.768370445162873e-07\n",
            "Epoch: 3  Batch: 7200  Loss: 0.0003361137059982866\n",
            "Epoch: 3  Batch: 7800  Loss: 2.5987286790041253e-05\n",
            "Epoch: 3  Batch: 8400  Loss: 0.0\n",
            "Epoch: 3  Batch: 9000  Loss: 2.264974000354414e-06\n",
            "Epoch: 3  Batch: 9600  Loss: 0.0\n",
            "Epoch: 3  Batch: 10200  Loss: 0.0\n",
            "Epoch: 3  Batch: 10800  Loss: 0.0\n",
            "Epoch: 3  Batch: 11400  Loss: 0.00011908298620255664\n",
            "Epoch: 3  Batch: 12000  Loss: 0.04526428505778313\n",
            "Epoch: 3  Batch: 12600  Loss: 1.1920928244535389e-07\n",
            "Epoch: 3  Batch: 13200  Loss: 0.0\n",
            "Epoch: 3  Batch: 13800  Loss: 0.0\n",
            "Epoch: 3  Batch: 14400  Loss: 0.0\n",
            "Epoch: 3  Batch: 15000  Loss: 0.0\n",
            "Epoch: 3  Batch: 15600  Loss: 0.0\n",
            "Epoch: 3  Batch: 16200  Loss: 0.0006157647585496306\n",
            "Epoch: 3  Batch: 16800  Loss: 9.536738616588991e-07\n",
            "Epoch: 3  Batch: 17400  Loss: 1.1324817933200393e-05\n",
            "Epoch: 3  Batch: 18000  Loss: 0.0\n",
            "Epoch: 3  Batch: 18600  Loss: 0.0012957995058968663\n",
            "Epoch: 3  Batch: 19200  Loss: 1.1920922133867862e-06\n",
            "Epoch: 3  Batch: 19800  Loss: 2.312633478140924e-05\n",
            "Epoch: 3  Batch: 20400  Loss: 0.0\n",
            "Epoch: 3  Batch: 21000  Loss: 8.34461570775602e-06\n",
            "Epoch: 3  Batch: 21600  Loss: 0.0\n",
            "Epoch: 3  Batch: 22200  Loss: 9.059865078597795e-06\n",
            "Epoch: 3  Batch: 22800  Loss: 0.0\n",
            "Epoch: 3  Batch: 23400  Loss: 0.003355232300236821\n",
            "Epoch: 3  Batch: 24000  Loss: 0.00026294111739844084\n",
            "Epoch: 3  Batch: 24600  Loss: 0.14921435713768005\n",
            "Epoch: 3  Batch: 25200  Loss: 1.3708974620385561e-05\n",
            "Epoch: 3  Batch: 25800  Loss: 2.3841855067985307e-07\n",
            "Epoch: 3  Batch: 26400  Loss: 4.768370445162873e-07\n",
            "Epoch: 3  Batch: 27000  Loss: 3.182837463100441e-05\n",
            "Epoch: 3  Batch: 27600  Loss: 0.0009154658182524145\n",
            "Epoch: 3  Batch: 28200  Loss: 0.0\n",
            "Epoch: 3  Batch: 28800  Loss: 0.0\n",
            "Epoch: 3  Batch: 29400  Loss: 0.0\n",
            "Epoch: 3  Batch: 30000  Loss: 8.344646857949556e-07\n",
            "Epoch: 3  Batch: 30600  Loss: 0.03003549762070179\n",
            "Epoch: 3  Batch: 31200  Loss: 0.0\n",
            "Epoch: 3  Batch: 31800  Loss: 0.0\n",
            "Epoch: 3  Batch: 32400  Loss: 0.0\n",
            "Epoch: 3  Batch: 33000  Loss: 0.0013188959565013647\n",
            "Epoch: 3  Batch: 33600  Loss: 0.006042071618139744\n",
            "Epoch: 3  Batch: 34200  Loss: 0.00040260792593471706\n",
            "Epoch: 3  Batch: 34800  Loss: 3.576278118089249e-07\n",
            "Epoch: 3  Batch: 35400  Loss: 1.1324817933200393e-05\n",
            "Epoch: 3  Batch: 36000  Loss: 1.1920928244535389e-07\n",
            "Epoch: 3  Batch: 36600  Loss: 2.753696753643453e-05\n",
            "Epoch: 3  Batch: 37200  Loss: 0.0\n",
            "Epoch: 3  Batch: 37800  Loss: 0.0\n",
            "Epoch: 3  Batch: 38400  Loss: 1.1920928244535389e-07\n",
            "Epoch: 3  Batch: 39000  Loss: 0.0\n",
            "Epoch: 3  Batch: 39600  Loss: 0.0002644904307089746\n",
            "Epoch: 3  Batch: 40200  Loss: 0.0\n",
            "Epoch: 3  Batch: 40800  Loss: 1.1920928244535389e-07\n",
            "Epoch: 3  Batch: 41400  Loss: 5.960462772236497e-07\n",
            "Epoch: 3  Batch: 42000  Loss: 4.768370445162873e-07\n",
            "Epoch: 3  Batch: 42600  Loss: 4.1960789531003684e-05\n",
            "Epoch: 3  Batch: 43200  Loss: 3.2186455882765586e-06\n",
            "Epoch: 3  Batch: 43800  Loss: 0.5524640083312988\n",
            "Epoch: 3  Batch: 44400  Loss: 0.0\n",
            "Epoch: 3  Batch: 45000  Loss: 0.0004864939546678215\n",
            "Epoch: 3  Batch: 45600  Loss: 0.0006252956227399409\n",
            "Epoch: 3  Batch: 46200  Loss: 0.00839313305914402\n",
            "Epoch: 3  Batch: 46800  Loss: 0.0\n",
            "Epoch: 3  Batch: 47400  Loss: 0.0\n",
            "Epoch: 3  Batch: 48000  Loss: 0.010199567303061485\n",
            "Epoch: 3  Batch: 48600  Loss: 0.040027420967817307\n",
            "Epoch: 3  Batch: 49200  Loss: 0.0\n",
            "Epoch: 3  Batch: 49800  Loss: 1.1920922133867862e-06\n",
            "Epoch: 3  Batch: 50400  Loss: 0.05041798576712608\n",
            "Epoch: 3  Batch: 51000  Loss: 0.0\n",
            "Epoch: 3  Batch: 51600  Loss: 9.667406266089529e-05\n",
            "Epoch: 3  Batch: 52200  Loss: 3.576278118089249e-07\n",
            "Epoch: 3  Batch: 52800  Loss: 2.8490614567999728e-05\n",
            "Epoch: 3  Batch: 53400  Loss: 0.00041345154750160873\n",
            "Epoch: 3  Batch: 54000  Loss: 0.0\n",
            "Epoch: 3  Batch: 54600  Loss: 0.00040570611599832773\n",
            "Epoch: 3  Batch: 55200  Loss: 3.576278118089249e-07\n",
            "Epoch: 3  Batch: 55800  Loss: 9.536738616588991e-07\n",
            "Epoch: 3  Batch: 56400  Loss: 0.0\n",
            "Epoch: 3  Batch: 57000  Loss: 4.768370445162873e-07\n",
            "Epoch: 3  Batch: 57600  Loss: 0.0005814530304633081\n",
            "Epoch: 3  Batch: 58200  Loss: 0.0\n",
            "Epoch: 3  Batch: 58800  Loss: 0.004376476630568504\n",
            "Epoch: 3  Batch: 59400  Loss: 2.3841855067985307e-07\n",
            "Epoch: 3  Batch: 60000  Loss: 0.00026008085114881396\n",
            "Epoch: 4  Batch: 600  Loss: 3.516612196108326e-05\n",
            "Epoch: 4  Batch: 1200  Loss: 0.0\n",
            "Epoch: 4  Batch: 1800  Loss: 0.09657854586839676\n",
            "Epoch: 4  Batch: 2400  Loss: 3.2305197237292305e-05\n",
            "Epoch: 4  Batch: 3000  Loss: 1.1920928244535389e-07\n",
            "Epoch: 4  Batch: 3600  Loss: 0.003960860893130302\n",
            "Epoch: 4  Batch: 4200  Loss: 0.14130941033363342\n",
            "Epoch: 4  Batch: 4800  Loss: 0.0\n",
            "Epoch: 4  Batch: 5400  Loss: 0.00013422065239865333\n",
            "Epoch: 4  Batch: 6000  Loss: 5.960462772236497e-07\n",
            "Epoch: 4  Batch: 6600  Loss: 7.152555099310121e-07\n",
            "Epoch: 4  Batch: 7200  Loss: 2.3841855067985307e-07\n",
            "Epoch: 4  Batch: 7800  Loss: 0.0\n",
            "Epoch: 4  Batch: 8400  Loss: 0.0\n",
            "Epoch: 4  Batch: 9000  Loss: 0.0\n",
            "Epoch: 4  Batch: 9600  Loss: 0.0\n",
            "Epoch: 4  Batch: 10200  Loss: 0.002997669158503413\n",
            "Epoch: 4  Batch: 10800  Loss: 0.0\n",
            "Epoch: 4  Batch: 11400  Loss: 0.0\n",
            "Epoch: 4  Batch: 12000  Loss: 0.0\n",
            "Epoch: 4  Batch: 12600  Loss: 0.0\n",
            "Epoch: 4  Batch: 13200  Loss: 0.0\n",
            "Epoch: 4  Batch: 13800  Loss: 9.011816291604191e-05\n",
            "Epoch: 4  Batch: 14400  Loss: 0.0\n",
            "Epoch: 4  Batch: 15000  Loss: 0.0\n",
            "Epoch: 4  Batch: 15600  Loss: 2.5152843591058627e-05\n",
            "Epoch: 4  Batch: 16200  Loss: 0.0\n",
            "Epoch: 4  Batch: 16800  Loss: 0.0\n",
            "Epoch: 4  Batch: 17400  Loss: 0.0\n",
            "Epoch: 4  Batch: 18000  Loss: 0.0\n",
            "Epoch: 4  Batch: 18600  Loss: 0.0\n",
            "Epoch: 4  Batch: 19200  Loss: 0.0\n",
            "Epoch: 4  Batch: 19800  Loss: 0.0\n",
            "Epoch: 4  Batch: 20400  Loss: 0.0\n",
            "Epoch: 4  Batch: 21000  Loss: 0.00018285033002030104\n",
            "Epoch: 4  Batch: 21600  Loss: 0.0\n",
            "Epoch: 4  Batch: 22200  Loss: 4.541770613286644e-05\n",
            "Epoch: 4  Batch: 22800  Loss: 0.0\n",
            "Epoch: 4  Batch: 23400  Loss: 2.50339189733495e-06\n",
            "Epoch: 4  Batch: 24000  Loss: 4.029192859889008e-05\n",
            "Epoch: 4  Batch: 24600  Loss: 0.0005265279905870557\n",
            "Epoch: 4  Batch: 25200  Loss: 0.0019921474158763885\n",
            "Epoch: 4  Batch: 25800  Loss: 4.005352093372494e-05\n",
            "Epoch: 4  Batch: 26400  Loss: 0.0\n",
            "Epoch: 4  Batch: 27000  Loss: 0.0006986799417063594\n",
            "Epoch: 4  Batch: 27600  Loss: 0.0703222006559372\n",
            "Epoch: 4  Batch: 28200  Loss: 0.02983858808875084\n",
            "Epoch: 4  Batch: 28800  Loss: 0.0\n",
            "Epoch: 4  Batch: 29400  Loss: 2.145764938177308e-06\n",
            "Epoch: 4  Batch: 30000  Loss: 1.4305104514278355e-06\n",
            "Epoch: 4  Batch: 30600  Loss: 0.0\n",
            "Epoch: 4  Batch: 31200  Loss: 0.0\n",
            "Epoch: 4  Batch: 31800  Loss: 4.8874615458771586e-05\n",
            "Epoch: 4  Batch: 32400  Loss: 0.0\n",
            "Epoch: 4  Batch: 33000  Loss: 0.0022991669829934835\n",
            "Epoch: 4  Batch: 33600  Loss: 3.576272320060525e-06\n",
            "Epoch: 4  Batch: 34200  Loss: 1.1920928244535389e-07\n",
            "Epoch: 4  Batch: 34800  Loss: 4.768370445162873e-07\n",
            "Epoch: 4  Batch: 35400  Loss: 0.0\n",
            "Epoch: 4  Batch: 36000  Loss: 1.5616295058862306e-05\n",
            "Epoch: 4  Batch: 36600  Loss: 1.0779528617858887\n",
            "Epoch: 4  Batch: 37200  Loss: 3.886147169396281e-05\n",
            "Epoch: 4  Batch: 37800  Loss: 2.264974000354414e-06\n",
            "Epoch: 4  Batch: 38400  Loss: 1.0371154530730564e-05\n",
            "Epoch: 4  Batch: 39000  Loss: 0.013388960622251034\n",
            "Epoch: 4  Batch: 39600  Loss: 0.009349845349788666\n",
            "Epoch: 4  Batch: 40200  Loss: 8.344646857949556e-07\n",
            "Epoch: 4  Batch: 40800  Loss: 0.0\n",
            "Epoch: 4  Batch: 41400  Loss: 1.1920928244535389e-07\n",
            "Epoch: 4  Batch: 42000  Loss: 0.0\n",
            "Epoch: 4  Batch: 42600  Loss: 2.3841855067985307e-07\n",
            "Epoch: 4  Batch: 43200  Loss: 4.768370445162873e-07\n",
            "Epoch: 4  Batch: 43800  Loss: 0.0\n",
            "Epoch: 4  Batch: 44400  Loss: 0.0\n",
            "Epoch: 4  Batch: 45000  Loss: 4.410646579344757e-05\n",
            "Epoch: 4  Batch: 45600  Loss: 1.1920928244535389e-07\n",
            "Epoch: 4  Batch: 46200  Loss: 0.39465203881263733\n",
            "Epoch: 4  Batch: 46800  Loss: 0.0\n",
            "Epoch: 4  Batch: 47400  Loss: 6.615896563744172e-05\n",
            "Epoch: 4  Batch: 48000  Loss: 0.0\n",
            "Epoch: 4  Batch: 48600  Loss: 6.747018051100895e-05\n",
            "Epoch: 4  Batch: 49200  Loss: 0.0\n",
            "Epoch: 4  Batch: 49800  Loss: 0.0\n",
            "Epoch: 4  Batch: 50400  Loss: 0.0\n",
            "Epoch: 4  Batch: 51000  Loss: 0.022157490253448486\n",
            "Epoch: 4  Batch: 51600  Loss: 3.182837463100441e-05\n",
            "Epoch: 4  Batch: 52200  Loss: 0.0\n",
            "Epoch: 4  Batch: 52800  Loss: 0.01246695313602686\n",
            "Epoch: 4  Batch: 53400  Loss: 0.0\n",
            "Epoch: 4  Batch: 54000  Loss: 0.0\n",
            "Epoch: 4  Batch: 54600  Loss: 0.0\n",
            "Epoch: 4  Batch: 55200  Loss: 9.298280929215252e-06\n",
            "Epoch: 4  Batch: 55800  Loss: 0.00011848701251437888\n",
            "Epoch: 4  Batch: 56400  Loss: 1.156323378381785e-05\n",
            "Epoch: 4  Batch: 57000  Loss: 0.0\n",
            "Epoch: 4  Batch: 57600  Loss: 0.0\n",
            "Epoch: 4  Batch: 58200  Loss: 5.960462772236497e-07\n",
            "Epoch: 4  Batch: 58800  Loss: 0.0\n",
            "Epoch: 4  Batch: 59400  Loss: 3.4570634852570947e-06\n",
            "Epoch: 4  Batch: 60000  Loss: 1.811964830267243e-05\n",
            "Training Took: 1548.9644644260406/60 minutes!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Graph the Loss at epoch\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.plot(test_losses, label='Test Loss')\n",
        "plt.title('Loss at Epoch')\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "zKcNgtO7Mx-6",
        "outputId": "d842fd60-1f80-49b0-fb59-ea101b30eda1"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7e1a777fb6d0>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bVQQMcwIO5B5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}