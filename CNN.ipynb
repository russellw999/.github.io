{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFAdzu8vlaOuBf+pHx7ddB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/russellw999/PyTorch-Tutorial-YouTube-Codemy/blob/master/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONrkbqVICCoA"
      },
      "outputs": [],
      "source": [
        "# Video 14 Convoluted neural Network - Import MNIST Images - Deep Learning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from io import IncrementalNewlineDecoder\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "%matplotlib inline\n"
      ],
      "metadata": {
        "id": "1yzEuxQrCTQ2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Images are 2 D but we need extra dimensions\n",
        "# Convert MNIS Image Files into a TENSOR OF 4-dimensions ( # of images, Height, Width, Color Channel)\n",
        "transform = transforms.ToTensor()\n"
      ],
      "metadata": {
        "id": "zfidFXOEDV5K"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Data\n",
        "train_data = datasets.MNIST(root='/cnn_data', train=True, download=True, transform=transform)"
      ],
      "metadata": {
        "id": "r7_PA3ijJl0x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fef9d22a-ebc0-489f-9f57-6767aa57f59b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:01<00:00, 5.26MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 154kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.46MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 6.32MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = datasets.MNIST(root='/cnn_data', train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "id": "O34jdZqhJ08i"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUinN4diKMbw",
        "outputId": "8fd0d1b5-eb06-4243-ea38-efcb217e0306"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: /cnn_data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORec0p6-KQ0w",
        "outputId": "33352f2f-ec8c-43ce-e32a-ff063ca15491"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 10000\n",
              "    Root location: /cnn_data\n",
              "    Split: Test\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# End of of Video 14 -\n",
        "#.  set up the CNN, Imported required libraries, created a transform to change the images to a 4 D tensor\n",
        "#   set up the training data downloaed and installed, set up the test data\n",
        "\n"
      ],
      "metadata": {
        "id": "vyheA5mxKYN8"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Video 15 Build the CNN\n",
        "\n",
        "# Create a small batch size for images...let's say 10\n",
        "train_loader = DataLoader(train_data, batch_size=1, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=1, shuffle=False)"
      ],
      "metadata": {
        "id": "ZacAe-0lKewO"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Our CNN Model\n",
        "# Describe convolutional layer and what it's doing ( 2 convolutional layers)\n",
        "# This is just an example the next video will build out the model\n",
        "\n",
        "#\n",
        "# conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=(3,3))\n",
        "# conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=(3,3))\n",
        "conv1 = nn.Conv2d(1, 6, 3, 1)\n",
        "conv2 = nn.Conv2d(6, 16, 3, 1)"
      ],
      "metadata": {
        "id": "4p5_sZjyVScE"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grab 1 MNIS record/image\n",
        "for i, (X_train, y_train) in enumerate(train_loader):\n",
        "    break"
      ],
      "metadata": {
        "id": "Kd76C9YHW54S"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ay6mG0JTXVU_",
        "outputId": "4d7e0e41-52d4-4224-ab49-c9564e753da5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.1294, 0.9098, 0.1882, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.4941, 0.9961, 0.8980, 0.0471,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.4941, 0.9961, 0.9961, 0.0627,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.2392, 0.9961, 0.9961, 0.1333,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0196, 0.7294, 0.9961, 0.4902,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6392, 0.9961, 0.5020,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6392, 0.9961, 0.9137,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6392, 0.9961, 0.9137,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6392, 0.9961, 0.9137,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6392, 0.9961, 0.8196,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6392, 0.9961, 0.4902,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6392, 0.9961, 0.4902,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0431, 0.8784, 0.9961, 0.4902,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0667, 0.9961, 0.9961, 0.1412,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.4784, 0.9961, 0.8039, 0.0314,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.7804, 1.0000, 0.6353, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.9176, 0.9961, 0.6353, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.9176, 0.9961, 0.6353, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.9176, 0.9961, 0.6353, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.3725, 0.7255, 0.3647, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-mkxlJ2XuV8",
        "outputId": "299cc215-03b9-4de0-ed62-09799fe9df41"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = X_train.view(1,1,28,28)  # change to 4 dimensional.  1 batch of 1 image of 28 x 28\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkK49FzaXz7A",
        "outputId": "10a86d98-32f4-4cd4-f3ec-b2eb8c0f804b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.1294, 0.9098, 0.1882, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.4941, 0.9961, 0.8980, 0.0471,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.4941, 0.9961, 0.9961, 0.0627,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.2392, 0.9961, 0.9961, 0.1333,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0196, 0.7294, 0.9961, 0.4902,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6392, 0.9961, 0.5020,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6392, 0.9961, 0.9137,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6392, 0.9961, 0.9137,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6392, 0.9961, 0.9137,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6392, 0.9961, 0.8196,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6392, 0.9961, 0.4902,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6392, 0.9961, 0.4902,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0431, 0.8784, 0.9961, 0.4902,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0667, 0.9961, 0.9961, 0.1412,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.4784, 0.9961, 0.8039, 0.0314,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.7804, 1.0000, 0.6353, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.9176, 0.9961, 0.6353, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.9176, 0.9961, 0.6353, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.9176, 0.9961, 0.6353, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.3725, 0.7255, 0.3647, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform our first convolution\n",
        "x = F.relu(conv1(x)) # Rectified Linear Unit for our activation function\n"
      ],
      "metadata": {
        "id": "ARoU7qHthHVR"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 single image, 6 is the filters we asked for, 26x26 is the image ( not 28x28 as the padding was removed)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sY1dFfqRh1Ot",
        "outputId": "0a5c77b8-067d-40cd-e12c-57c196796411"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 6, 26, 26])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pass thru the pooling layer\n",
        "\n",
        "x = F.max_pool2d(x, 2, 2) # kernal of 2 and stride of 2"
      ],
      "metadata": {
        "id": "atkC2m01i8dA"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape  # 26 / 2 = 13  (stride was set to 2 in previous step)"
      ],
      "metadata": {
        "id": "YiC7XqfcjZT8",
        "outputId": "82121af9-30a5-4d7a-cef8-bf2cedf14370",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 6, 13, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Do our second convolutional layer.  (same x as its all linear one after the otehr)\n",
        "x = F.relu(conv2(x))  #. conv2 is ( 6, 16, 3, 1)"
      ],
      "metadata": {
        "id": "rU00ndIJjoUM"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape   # Again we did not set padding so we lose 2 px around the outside of image"
      ],
      "metadata": {
        "id": "AzHbJubWj_Qg",
        "outputId": "0f23985e-399f-4796-fb02-32129247e341",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 16, 11, 11])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pooling layer\n",
        "x = F.max_pool2d(x, 2, 2)"
      ],
      "metadata": {
        "id": "8Db_0Pz3kPEA"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape # 11/2 = 5.5 but we have to rounddown , because you can't invent data to round up"
      ],
      "metadata": {
        "id": "pdaupdqBkWlJ",
        "outputId": "35e4a75c-57e3-4304-d390-ee42f566afac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 16, 5, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# End of Video 15 - we have taken an image and passed it through 2 convolutions and poolings"
      ],
      "metadata": {
        "id": "i8lurPMkki4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Video 17 Builld a Model"
      ],
      "metadata": {
        "id": "GrEjwV_f6er1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Class\n",
        "class ConvolutionalNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(1,6,3,1)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 3,1)\n",
        "    # Fully Connected Layer\n",
        "    self.fc1 = nn.Linear(5*5*16, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, X):\n",
        "    X = F.relu(self.conv1(X))\n",
        "    X = F.max_pool2d(X, 2,2)   # 2x2 kernal and stride 2\n",
        "    # Second Pass\n",
        "    X = F.relu(self.conv2(X))\n",
        "    X = F.max_pool2d(X, 2,2)   # 2x2 kernal and stride 2\n",
        "\n",
        "    # Re-View to flatten out\n",
        "    X = X.view(-1, 16*5*5)   # -1 one so that we can vary the batch size\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    X = F.relu(self.fc1(X))\n",
        "    X = F.relu(self.fc2(X))\n",
        "    X = self.fc3(X)\n",
        "\n",
        "    return F.log_softmax(X, dim=1)\n"
      ],
      "metadata": {
        "id": "sb1tXejE66JX"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an Instance of our Model\n",
        "torch.manual_seed(41)\n",
        "model = ConvolutionalNetwork()\n",
        "\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vn3bMaqu-_wc",
        "outputId": "23704dec-4693-4bbd-d390-c271ebc4eb52"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvolutionalNetwork(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss Function Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # Smaller the Learning Rate, the longer it takes to train"
      ],
      "metadata": {
        "id": "vehZDXL6_k8i"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# End of Video 16 Create model\n",
        "# Start of Video 17 Train Data"
      ],
      "metadata": {
        "id": "bPZVGxT8ABtj"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "# Create variables to Track Things\n",
        "epochs = 5\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_correct = []\n",
        "test_correct = []\n",
        "\n",
        "#   For Loop of Epochs\n",
        "for i in range(epochs):\n",
        "  trn_corr = 0\n",
        "  tst_corr = 0\n",
        "\n",
        "  # Train\n",
        "  for b,(X_train, y_train) in enumerate(train_loader):\n",
        "      b+=1\n",
        "      # Apply our model\n",
        "      y_pred = model(X_train)  # get the predicteds values from the training set, Not flattened 2D\n",
        "      loss = criterion(y_pred, y_train) # how off are we? Compare the predictions to correct answers in Y_train\n",
        "\n",
        "      predicted = torch.max(y_pred.data,1)[1] # add up the number of correct predictions. Indexed off the first point\n",
        "      batch_correct = (predicted == y_train).sum() # how many we got correct from this batch. True = 1, False = 0, sum those up\n",
        "      trn_corr += batch_correct # add up the number of correct predictions\n",
        "\n",
        "      # Update our parameters\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "\n",
        "      # Print out some results\n",
        "      if b%600 == 0:\n",
        "        print(f'Epoch: {i}  Batch: {b}  Loss: {loss.item()}')\n",
        "\n",
        "  train_losses.append(loss)\n",
        "  train_correct.append(trn_corr)\n",
        "\n",
        "  # Test\n",
        "  with torch.no_grad():     # No gradient so we don't update our weights abd biases with test\n",
        "      for b, (X_test, y_test) in enumerate(test_loader):\n",
        "        y_val = model(X_test)\n",
        "        predicted = torch.max(y_val.data, 1)[1] # Adding up correct predictions\n",
        "        tst_corr += (predicted == y_test).sum()\n",
        "\n",
        "  loss = criterion(y_val, y_test)\n",
        "  test_losses.append(loss)\n",
        "  test_correct.append(tst_corr)\n",
        "\n",
        "\n",
        "\n",
        "current_time = time.time()\n",
        "elapsed_time = current_time - start_time\n",
        "print(f'Training Took: {elapsed_time/60}minutes!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hdJfwe4AZ6k",
        "outputId": "0b84e3a6-3409-4c6e-838b-7b13951d9db3"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0  Batch: 600  Loss: 0.08787637948989868\n",
            "Epoch: 0  Batch: 1200  Loss: 2.5110254287719727\n",
            "Epoch: 0  Batch: 1800  Loss: 0.14741575717926025\n",
            "Epoch: 0  Batch: 2400  Loss: 2.3756425380706787\n",
            "Epoch: 0  Batch: 3000  Loss: 0.0034033493138849735\n",
            "Epoch: 0  Batch: 3600  Loss: 0.060373492538928986\n",
            "Epoch: 0  Batch: 4200  Loss: 0.0048146978951990604\n",
            "Epoch: 0  Batch: 4800  Loss: 0.020903753116726875\n",
            "Epoch: 0  Batch: 5400  Loss: 0.0005940818227827549\n",
            "Epoch: 0  Batch: 6000  Loss: 0.0009480987209826708\n",
            "Epoch: 0  Batch: 6600  Loss: 4.2676016164477915e-05\n",
            "Epoch: 0  Batch: 7200  Loss: 0.002409889828413725\n",
            "Epoch: 0  Batch: 7800  Loss: 1.811964830267243e-05\n",
            "Epoch: 0  Batch: 8400  Loss: 0.00024172721896320581\n",
            "Epoch: 0  Batch: 9000  Loss: 0.0003297977091278881\n",
            "Epoch: 0  Batch: 9600  Loss: 0.0015156697481870651\n",
            "Epoch: 0  Batch: 10200  Loss: 0.002953574061393738\n",
            "Epoch: 0  Batch: 10800  Loss: 0.002577556297183037\n",
            "Epoch: 0  Batch: 11400  Loss: 0.0009893052047118545\n",
            "Epoch: 0  Batch: 12000  Loss: 0.00021479207498487085\n",
            "Epoch: 0  Batch: 12600  Loss: 0.3600896894931793\n",
            "Epoch: 0  Batch: 13200  Loss: 5.817244164063595e-05\n",
            "Epoch: 0  Batch: 13800  Loss: 0.135885089635849\n",
            "Epoch: 0  Batch: 14400  Loss: 5.125986263010418e-06\n",
            "Epoch: 0  Batch: 15000  Loss: 0.016545584425330162\n",
            "Epoch: 0  Batch: 15600  Loss: 3.194758028257638e-05\n",
            "Epoch: 0  Batch: 16200  Loss: 2.622600959512056e-06\n",
            "Epoch: 0  Batch: 16800  Loss: 0.06772375851869583\n",
            "Epoch: 0  Batch: 17400  Loss: 0.66081702709198\n",
            "Epoch: 0  Batch: 18000  Loss: 0.0008709213580004871\n",
            "Epoch: 0  Batch: 18600  Loss: 1.549708758830093e-05\n",
            "Epoch: 0  Batch: 19200  Loss: 0.00026306029758416116\n",
            "Epoch: 0  Batch: 19800  Loss: 0.02193254791200161\n",
            "Epoch: 0  Batch: 20400  Loss: 0.0005548844928853214\n",
            "Epoch: 0  Batch: 21000  Loss: 0.8111323714256287\n",
            "Epoch: 0  Batch: 21600  Loss: 4.6132929128361866e-05\n",
            "Epoch: 0  Batch: 22200  Loss: 0.5408194661140442\n",
            "Epoch: 0  Batch: 22800  Loss: 0.007523180451244116\n",
            "Epoch: 0  Batch: 23400  Loss: 1.1920928244535389e-07\n",
            "Epoch: 0  Batch: 24000  Loss: 0.0006932000978849828\n",
            "Epoch: 0  Batch: 24600  Loss: 0.002448301063850522\n",
            "Epoch: 0  Batch: 25200  Loss: 0.021474698558449745\n",
            "Epoch: 0  Batch: 25800  Loss: 8.654219709569588e-05\n",
            "Epoch: 0  Batch: 26400  Loss: 1.4755313396453857\n",
            "Epoch: 0  Batch: 27000  Loss: 9.762764238985255e-05\n",
            "Epoch: 0  Batch: 27600  Loss: 0.0\n",
            "Epoch: 0  Batch: 28200  Loss: 3.576278118089249e-07\n",
            "Epoch: 0  Batch: 28800  Loss: 2.0265373677830212e-05\n",
            "Epoch: 0  Batch: 29400  Loss: 0.00022301571152638644\n",
            "Epoch: 0  Batch: 30000  Loss: 2.372236667724792e-05\n",
            "Epoch: 0  Batch: 30600  Loss: 0.026774199679493904\n",
            "Epoch: 0  Batch: 31200  Loss: 0.022593233734369278\n",
            "Epoch: 0  Batch: 31800  Loss: 0.0\n",
            "Epoch: 0  Batch: 32400  Loss: 0.0001501924270996824\n",
            "Epoch: 0  Batch: 33000  Loss: 0.0008073169738054276\n",
            "Epoch: 0  Batch: 33600  Loss: 0.0014788892585784197\n",
            "Epoch: 0  Batch: 34200  Loss: 0.00015341058315243572\n",
            "Epoch: 0  Batch: 34800  Loss: 2.5033637939486653e-05\n",
            "Epoch: 0  Batch: 35400  Loss: 0.0\n",
            "Epoch: 0  Batch: 36000  Loss: 0.18889440596103668\n",
            "Epoch: 0  Batch: 36600  Loss: 0.42173802852630615\n",
            "Epoch: 0  Batch: 37200  Loss: 0.0010543270036578178\n",
            "Epoch: 0  Batch: 37800  Loss: 0.0005399914807640016\n",
            "Epoch: 0  Batch: 38400  Loss: 7.629365427419543e-06\n",
            "Epoch: 0  Batch: 39000  Loss: 0.0005947966128587723\n",
            "Epoch: 0  Batch: 39600  Loss: 1.1920922133867862e-06\n",
            "Epoch: 0  Batch: 40200  Loss: 0.0029273061081767082\n",
            "Epoch: 0  Batch: 40800  Loss: 0.04375215247273445\n",
            "Epoch: 0  Batch: 41400  Loss: 7.748573807475623e-06\n",
            "Epoch: 0  Batch: 42000  Loss: 0.00018857131362892687\n",
            "Epoch: 0  Batch: 42600  Loss: 2.7656173188006505e-05\n",
            "Epoch: 0  Batch: 43200  Loss: 1.311301275563892e-06\n",
            "Epoch: 0  Batch: 43800  Loss: 2.0265558760002023e-06\n",
            "Epoch: 0  Batch: 44400  Loss: 0.00702210608869791\n",
            "Epoch: 0  Batch: 45000  Loss: 8.344646857949556e-07\n",
            "Epoch: 0  Batch: 45600  Loss: 0.0062559256330132484\n",
            "Epoch: 0  Batch: 46200  Loss: 0.262514591217041\n",
            "Epoch: 0  Batch: 46800  Loss: 2.062299427052494e-05\n",
            "Epoch: 0  Batch: 47400  Loss: 0.04923665523529053\n",
            "Epoch: 0  Batch: 48000  Loss: 2.264974000354414e-06\n",
            "Epoch: 0  Batch: 48600  Loss: 0.0010926711838692427\n",
            "Epoch: 0  Batch: 49200  Loss: 0.031203782185912132\n",
            "Epoch: 0  Batch: 49800  Loss: 5.960462772236497e-07\n",
            "Epoch: 0  Batch: 50400  Loss: 0.039657413959503174\n",
            "Epoch: 0  Batch: 51000  Loss: 0.0\n",
            "Epoch: 0  Batch: 51600  Loss: 3.576278118089249e-07\n",
            "Epoch: 0  Batch: 52200  Loss: 0.005784912966191769\n",
            "Epoch: 0  Batch: 52800  Loss: 0.0015570909017696977\n",
            "Epoch: 0  Batch: 53400  Loss: 0.0007151191821321845\n",
            "Epoch: 0  Batch: 54000  Loss: 3.3378044463461265e-05\n",
            "Epoch: 0  Batch: 54600  Loss: 0.08801110088825226\n",
            "Epoch: 0  Batch: 55200  Loss: 0.0001161031104857102\n",
            "Epoch: 0  Batch: 55800  Loss: 0.0\n",
            "Epoch: 0  Batch: 56400  Loss: 1.0629326105117798\n",
            "Epoch: 0  Batch: 57000  Loss: 0.000675807474181056\n",
            "Epoch: 0  Batch: 57600  Loss: 0.0\n",
            "Epoch: 0  Batch: 58200  Loss: 0.0198720283806324\n",
            "Epoch: 0  Batch: 58800  Loss: 0.0014541300479322672\n",
            "Epoch: 0  Batch: 59400  Loss: 5.483612312673358e-06\n",
            "Epoch: 0  Batch: 60000  Loss: 5.435795901576057e-05\n",
            "Epoch: 1  Batch: 600  Loss: 0.00021884430316276848\n",
            "Epoch: 1  Batch: 1200  Loss: 5.960462772236497e-07\n",
            "Epoch: 1  Batch: 1800  Loss: 0.029333408921957016\n",
            "Epoch: 1  Batch: 2400  Loss: 0.0002441108226776123\n",
            "Epoch: 1  Batch: 3000  Loss: 0.00048744716332294047\n",
            "Epoch: 1  Batch: 3600  Loss: 0.00029476112104021013\n",
            "Epoch: 1  Batch: 4200  Loss: 0.008642295375466347\n",
            "Epoch: 1  Batch: 4800  Loss: 0.0\n",
            "Epoch: 1  Batch: 5400  Loss: 0.036424294114112854\n",
            "Epoch: 1  Batch: 6000  Loss: 0.00015877417172305286\n",
            "Epoch: 1  Batch: 6600  Loss: 0.0\n",
            "Epoch: 1  Batch: 7200  Loss: 2.3841855067985307e-07\n",
            "Epoch: 1  Batch: 7800  Loss: 0.0\n",
            "Epoch: 1  Batch: 8400  Loss: 0.006627128459513187\n",
            "Epoch: 1  Batch: 9000  Loss: 2.6940935640595853e-05\n",
            "Epoch: 1  Batch: 9600  Loss: 0.0\n",
            "Epoch: 1  Batch: 10200  Loss: 9.202533692587167e-05\n",
            "Epoch: 1  Batch: 10800  Loss: 5.602820692729438e-06\n",
            "Epoch: 1  Batch: 11400  Loss: 2.0265558760002023e-06\n",
            "Epoch: 1  Batch: 12000  Loss: 4.768370445162873e-07\n",
            "Epoch: 1  Batch: 12600  Loss: 1.9073468138230965e-06\n",
            "Epoch: 1  Batch: 13200  Loss: 3.3001279830932617\n",
            "Epoch: 1  Batch: 13800  Loss: 6.079655122448457e-06\n",
            "Epoch: 1  Batch: 14400  Loss: 0.0004576589271891862\n",
            "Epoch: 1  Batch: 15000  Loss: 2.5629668016335927e-05\n",
            "Epoch: 1  Batch: 15600  Loss: 1.2397689715726301e-05\n",
            "Epoch: 1  Batch: 16200  Loss: 1.1920928244535389e-07\n",
            "Epoch: 1  Batch: 16800  Loss: 1.0132738680113107e-05\n",
            "Epoch: 1  Batch: 17400  Loss: 0.01692904531955719\n",
            "Epoch: 1  Batch: 18000  Loss: 1.1920928244535389e-07\n",
            "Epoch: 1  Batch: 18600  Loss: 6.079655122448457e-06\n",
            "Epoch: 1  Batch: 19200  Loss: 3.4927710657939315e-05\n",
            "Epoch: 1  Batch: 19800  Loss: 0.00910853873938322\n",
            "Epoch: 1  Batch: 20400  Loss: 0.0022144813556224108\n",
            "Epoch: 1  Batch: 21000  Loss: 0.00034624303225427866\n",
            "Epoch: 1  Batch: 21600  Loss: 4.529942543740617e-06\n",
            "Epoch: 1  Batch: 22200  Loss: 0.00739704817533493\n",
            "Epoch: 1  Batch: 22800  Loss: 2.622600959512056e-06\n",
            "Epoch: 1  Batch: 23400  Loss: 3.1470757676288486e-05\n",
            "Epoch: 1  Batch: 24000  Loss: 1.4305104514278355e-06\n",
            "Epoch: 1  Batch: 24600  Loss: 0.0002299282787134871\n",
            "Epoch: 1  Batch: 25200  Loss: 0.0\n",
            "Epoch: 1  Batch: 25800  Loss: 1.1280848979949951\n",
            "Epoch: 1  Batch: 26400  Loss: 2.9801878554280847e-05\n",
            "Epoch: 1  Batch: 27000  Loss: 0.00019107422849629074\n",
            "Epoch: 1  Batch: 27600  Loss: 3.576278118089249e-07\n",
            "Epoch: 1  Batch: 28200  Loss: 0.0003400462737772614\n",
            "Epoch: 1  Batch: 28800  Loss: 0.0\n",
            "Epoch: 1  Batch: 29400  Loss: 0.014992416836321354\n",
            "Epoch: 1  Batch: 30000  Loss: 1.168244216387393e-05\n",
            "Epoch: 1  Batch: 30600  Loss: 0.0\n",
            "Epoch: 1  Batch: 31200  Loss: 0.0001358893496217206\n",
            "Epoch: 1  Batch: 31800  Loss: 0.0\n",
            "Epoch: 1  Batch: 32400  Loss: 0.0\n",
            "Epoch: 1  Batch: 33000  Loss: 0.00943499244749546\n",
            "Epoch: 1  Batch: 33600  Loss: 0.0\n",
            "Epoch: 1  Batch: 34200  Loss: 8.618460560683161e-05\n",
            "Epoch: 1  Batch: 34800  Loss: 0.0018717404454946518\n",
            "Epoch: 1  Batch: 35400  Loss: 1.0728830375228426e-06\n",
            "Epoch: 1  Batch: 36000  Loss: 8.237022848334163e-05\n",
            "Epoch: 1  Batch: 36600  Loss: 0.0\n",
            "Epoch: 1  Batch: 37200  Loss: 1.1920928244535389e-07\n",
            "Epoch: 1  Batch: 37800  Loss: 0.0\n",
            "Epoch: 1  Batch: 38400  Loss: 0.023286443203687668\n",
            "Epoch: 1  Batch: 39000  Loss: 0.004806156270205975\n",
            "Epoch: 1  Batch: 39600  Loss: 3.3378546504536644e-06\n",
            "Epoch: 1  Batch: 40200  Loss: 1.7881377516459906e-06\n",
            "Epoch: 1  Batch: 40800  Loss: 0.0\n",
            "Epoch: 1  Batch: 41400  Loss: 0.0009363081189803779\n",
            "Epoch: 1  Batch: 42000  Loss: 0.00029059001826681197\n",
            "Epoch: 1  Batch: 42600  Loss: 3.099436753473128e-06\n",
            "Epoch: 1  Batch: 43200  Loss: 0.0\n",
            "Epoch: 1  Batch: 43800  Loss: 5.960462772236497e-07\n",
            "Epoch: 1  Batch: 44400  Loss: 0.0\n",
            "Epoch: 1  Batch: 45000  Loss: 0.049165502190589905\n",
            "Epoch: 1  Batch: 45600  Loss: 0.0\n",
            "Epoch: 1  Batch: 46200  Loss: 0.0\n",
            "Epoch: 1  Batch: 46800  Loss: 0.0\n",
            "Epoch: 1  Batch: 47400  Loss: 0.0\n",
            "Epoch: 1  Batch: 48000  Loss: 4.768370445162873e-07\n",
            "Epoch: 1  Batch: 48600  Loss: 2.0265558760002023e-06\n",
            "Epoch: 1  Batch: 49200  Loss: 2.264974000354414e-06\n",
            "Epoch: 1  Batch: 49800  Loss: 2.3841855067985307e-07\n",
            "Epoch: 1  Batch: 50400  Loss: 2.3841855067985307e-07\n",
            "Epoch: 1  Batch: 51000  Loss: 0.0\n",
            "Epoch: 1  Batch: 51600  Loss: 3.576278118089249e-07\n",
            "Epoch: 1  Batch: 52200  Loss: 1.1920928244535389e-07\n",
            "Epoch: 1  Batch: 52800  Loss: 0.0024758896324783564\n",
            "Epoch: 1  Batch: 53400  Loss: 2.396077979938127e-05\n",
            "Epoch: 1  Batch: 54000  Loss: 1.1920928244535389e-07\n",
            "Epoch: 1  Batch: 54600  Loss: 2.312633478140924e-05\n",
            "Epoch: 1  Batch: 55200  Loss: 0.0\n",
            "Epoch: 1  Batch: 55800  Loss: 1.1444026313256472e-05\n",
            "Epoch: 1  Batch: 56400  Loss: 0.6434429883956909\n",
            "Epoch: 1  Batch: 57000  Loss: 0.03101889044046402\n",
            "Epoch: 1  Batch: 57600  Loss: 0.0\n",
            "Epoch: 1  Batch: 58200  Loss: 0.006275709252804518\n",
            "Epoch: 1  Batch: 58800  Loss: 0.0\n",
            "Epoch: 1  Batch: 59400  Loss: 0.00014494798961095512\n",
            "Epoch: 1  Batch: 60000  Loss: 0.0046953423880040646\n",
            "Epoch: 2  Batch: 600  Loss: 0.0001867835089797154\n",
            "Epoch: 2  Batch: 1200  Loss: 0.0003093002596870065\n",
            "Epoch: 2  Batch: 1800  Loss: 0.0002526917669456452\n",
            "Epoch: 2  Batch: 2400  Loss: 0.00011002412065863609\n",
            "Epoch: 2  Batch: 3000  Loss: 0.0\n",
            "Epoch: 2  Batch: 3600  Loss: 2.3841855067985307e-07\n",
            "Epoch: 2  Batch: 4200  Loss: 0.0\n",
            "Epoch: 2  Batch: 4800  Loss: 8.22540732769994e-06\n",
            "Epoch: 2  Batch: 5400  Loss: 7.629365427419543e-06\n",
            "Epoch: 2  Batch: 6000  Loss: 1.4305104514278355e-06\n",
            "Epoch: 2  Batch: 6600  Loss: 0.00017033556650858372\n",
            "Epoch: 2  Batch: 7200  Loss: 8.618460560683161e-05\n",
            "Epoch: 2  Batch: 7800  Loss: 2.622600959512056e-06\n",
            "Epoch: 2  Batch: 8400  Loss: 0.0\n",
            "Epoch: 2  Batch: 9000  Loss: 4.9232225137529895e-05\n",
            "Epoch: 2  Batch: 9600  Loss: 0.0\n",
            "Epoch: 2  Batch: 10200  Loss: 1.1941378116607666\n",
            "Epoch: 2  Batch: 10800  Loss: 0.0\n",
            "Epoch: 2  Batch: 11400  Loss: 0.0\n",
            "Epoch: 2  Batch: 12000  Loss: 0.0\n",
            "Epoch: 2  Batch: 12600  Loss: 6.151010165922344e-05\n",
            "Epoch: 2  Batch: 13200  Loss: 0.9266853332519531\n",
            "Epoch: 2  Batch: 13800  Loss: 0.0009110590908676386\n",
            "Epoch: 2  Batch: 14400  Loss: 1.1920922133867862e-06\n",
            "Epoch: 2  Batch: 15000  Loss: 0.0\n",
            "Epoch: 2  Batch: 15600  Loss: 5.61460001335945e-05\n",
            "Epoch: 2  Batch: 16200  Loss: 0.003338004695251584\n",
            "Epoch: 2  Batch: 16800  Loss: 8.344646857949556e-07\n",
            "Epoch: 2  Batch: 17400  Loss: 0.0\n",
            "Epoch: 2  Batch: 18000  Loss: 0.0\n",
            "Epoch: 2  Batch: 18600  Loss: 2.3841855067985307e-07\n",
            "Epoch: 2  Batch: 19200  Loss: 0.0018079616129398346\n",
            "Epoch: 2  Batch: 19800  Loss: 1.364565372467041\n",
            "Epoch: 2  Batch: 20400  Loss: 0.0\n",
            "Epoch: 2  Batch: 21000  Loss: 0.0\n",
            "Epoch: 2  Batch: 21600  Loss: 2.3841855067985307e-07\n",
            "Epoch: 2  Batch: 22200  Loss: 0.0\n",
            "Epoch: 2  Batch: 22800  Loss: 0.0\n",
            "Epoch: 2  Batch: 23400  Loss: 0.13269264996051788\n",
            "Epoch: 2  Batch: 24000  Loss: 2.3841855067985307e-07\n",
            "Epoch: 2  Batch: 24600  Loss: 8.702239938429557e-06\n",
            "Epoch: 2  Batch: 25200  Loss: 0.0\n",
            "Epoch: 2  Batch: 25800  Loss: 0.0319790318608284\n",
            "Epoch: 2  Batch: 26400  Loss: 3.4570634852570947e-06\n",
            "Epoch: 2  Batch: 27000  Loss: 2.3841855067985307e-07\n",
            "Epoch: 2  Batch: 27600  Loss: 5.411955135059543e-05\n",
            "Epoch: 2  Batch: 28200  Loss: 0.0\n",
            "Epoch: 2  Batch: 28800  Loss: 0.004482341464608908\n",
            "Epoch: 2  Batch: 29400  Loss: 0.0\n",
            "Epoch: 2  Batch: 30000  Loss: 2.2889699935913086\n",
            "Epoch: 2  Batch: 30600  Loss: 0.006374858319759369\n",
            "Epoch: 2  Batch: 31200  Loss: 1.823885577323381e-05\n",
            "Epoch: 2  Batch: 31800  Loss: 0.0\n",
            "Epoch: 2  Batch: 32400  Loss: 0.0\n",
            "Epoch: 2  Batch: 33000  Loss: 0.0005837167263962328\n",
            "Epoch: 2  Batch: 33600  Loss: 1.8715683836489916e-05\n",
            "Epoch: 2  Batch: 34200  Loss: 0.0009977606823667884\n",
            "Epoch: 2  Batch: 34800  Loss: 7.748573807475623e-06\n",
            "Epoch: 2  Batch: 35400  Loss: 0.00015484087634831667\n",
            "Epoch: 2  Batch: 36000  Loss: 1.1920922133867862e-06\n",
            "Epoch: 2  Batch: 36600  Loss: 0.002664113650098443\n",
            "Epoch: 2  Batch: 37200  Loss: 6.675497570540756e-05\n",
            "Epoch: 2  Batch: 37800  Loss: 0.0\n",
            "Epoch: 2  Batch: 38400  Loss: 0.011508270166814327\n",
            "Epoch: 2  Batch: 39000  Loss: 0.0\n",
            "Epoch: 2  Batch: 39600  Loss: 0.0\n",
            "Epoch: 2  Batch: 40200  Loss: 0.0\n",
            "Epoch: 2  Batch: 40800  Loss: 3.576278118089249e-07\n",
            "Epoch: 2  Batch: 41400  Loss: 0.0\n",
            "Epoch: 2  Batch: 42000  Loss: 0.00010787858627736568\n",
            "Epoch: 2  Batch: 42600  Loss: 2.5912914276123047\n",
            "Epoch: 2  Batch: 43200  Loss: 0.0\n",
            "Epoch: 2  Batch: 43800  Loss: 1.2993727978027891e-05\n",
            "Epoch: 2  Batch: 44400  Loss: 0.7015290856361389\n",
            "Epoch: 2  Batch: 45000  Loss: 2.002696055569686e-05\n",
            "Epoch: 2  Batch: 45600  Loss: 0.0\n",
            "Epoch: 2  Batch: 46200  Loss: 0.007510283961892128\n",
            "Epoch: 2  Batch: 46800  Loss: 1.1920928244535389e-07\n",
            "Epoch: 2  Batch: 47400  Loss: 4.529942543740617e-06\n",
            "Epoch: 2  Batch: 48000  Loss: 0.0\n",
            "Epoch: 2  Batch: 48600  Loss: 0.0\n",
            "Epoch: 2  Batch: 49200  Loss: 5.245195097813848e-06\n",
            "Epoch: 2  Batch: 49800  Loss: 6.318072337307967e-06\n",
            "Epoch: 2  Batch: 50400  Loss: 0.0\n",
            "Epoch: 2  Batch: 51000  Loss: 0.0\n",
            "Epoch: 2  Batch: 51600  Loss: 1.1920928244535389e-07\n",
            "Epoch: 2  Batch: 52200  Loss: 0.0\n",
            "Epoch: 2  Batch: 52800  Loss: 5.638440416078083e-05\n",
            "Epoch: 2  Batch: 53400  Loss: 0.0\n",
            "Epoch: 2  Batch: 54000  Loss: 1.545701026916504\n",
            "Epoch: 2  Batch: 54600  Loss: 0.0\n",
            "Epoch: 2  Batch: 55200  Loss: 0.0009538153535686433\n",
            "Epoch: 2  Batch: 55800  Loss: 0.27190709114074707\n",
            "Epoch: 2  Batch: 56400  Loss: 0.0\n",
            "Epoch: 2  Batch: 57000  Loss: 0.0\n",
            "Epoch: 2  Batch: 57600  Loss: 0.0\n",
            "Epoch: 2  Batch: 58200  Loss: 0.003473916556686163\n",
            "Epoch: 2  Batch: 58800  Loss: 2.6225699912174605e-05\n",
            "Epoch: 2  Batch: 59400  Loss: 0.0013468727702274919\n",
            "Epoch: 2  Batch: 60000  Loss: 0.0015048381173983216\n",
            "Epoch: 3  Batch: 600  Loss: 0.0\n",
            "Epoch: 3  Batch: 1200  Loss: 0.0006790239713154733\n",
            "Epoch: 3  Batch: 1800  Loss: 0.0\n",
            "Epoch: 3  Batch: 2400  Loss: 0.0\n",
            "Epoch: 3  Batch: 3000  Loss: 0.0\n",
            "Epoch: 3  Batch: 3600  Loss: 0.0\n",
            "Epoch: 3  Batch: 4200  Loss: 2.3841855067985307e-07\n",
            "Epoch: 3  Batch: 4800  Loss: 6.83045873302035e-05\n",
            "Epoch: 3  Batch: 5400  Loss: 3.576278118089249e-07\n",
            "Epoch: 3  Batch: 6000  Loss: 2.5033637939486653e-05\n",
            "Epoch: 3  Batch: 6600  Loss: 4.768370445162873e-07\n",
            "Epoch: 3  Batch: 7200  Loss: 0.0003361137059982866\n",
            "Epoch: 3  Batch: 7800  Loss: 2.5987286790041253e-05\n",
            "Epoch: 3  Batch: 8400  Loss: 0.0\n",
            "Epoch: 3  Batch: 9000  Loss: 2.264974000354414e-06\n",
            "Epoch: 3  Batch: 9600  Loss: 0.0\n",
            "Epoch: 3  Batch: 10200  Loss: 0.0\n",
            "Epoch: 3  Batch: 10800  Loss: 0.0\n",
            "Epoch: 3  Batch: 11400  Loss: 0.00011908298620255664\n",
            "Epoch: 3  Batch: 12000  Loss: 0.04526428505778313\n",
            "Epoch: 3  Batch: 12600  Loss: 1.1920928244535389e-07\n",
            "Epoch: 3  Batch: 13200  Loss: 0.0\n",
            "Epoch: 3  Batch: 13800  Loss: 0.0\n",
            "Epoch: 3  Batch: 14400  Loss: 0.0\n",
            "Epoch: 3  Batch: 15000  Loss: 0.0\n",
            "Epoch: 3  Batch: 15600  Loss: 0.0\n",
            "Epoch: 3  Batch: 16200  Loss: 0.0006157647585496306\n",
            "Epoch: 3  Batch: 16800  Loss: 9.536738616588991e-07\n",
            "Epoch: 3  Batch: 17400  Loss: 1.1324817933200393e-05\n",
            "Epoch: 3  Batch: 18000  Loss: 0.0\n",
            "Epoch: 3  Batch: 18600  Loss: 0.0012957995058968663\n",
            "Epoch: 3  Batch: 19200  Loss: 1.1920922133867862e-06\n",
            "Epoch: 3  Batch: 19800  Loss: 2.312633478140924e-05\n",
            "Epoch: 3  Batch: 20400  Loss: 0.0\n",
            "Epoch: 3  Batch: 21000  Loss: 8.34461570775602e-06\n",
            "Epoch: 3  Batch: 21600  Loss: 0.0\n",
            "Epoch: 3  Batch: 22200  Loss: 9.059865078597795e-06\n",
            "Epoch: 3  Batch: 22800  Loss: 0.0\n",
            "Epoch: 3  Batch: 23400  Loss: 0.003355232300236821\n",
            "Epoch: 3  Batch: 24000  Loss: 0.00026294111739844084\n",
            "Epoch: 3  Batch: 24600  Loss: 0.14921435713768005\n",
            "Epoch: 3  Batch: 25200  Loss: 1.3708974620385561e-05\n",
            "Epoch: 3  Batch: 25800  Loss: 2.3841855067985307e-07\n",
            "Epoch: 3  Batch: 26400  Loss: 4.768370445162873e-07\n",
            "Epoch: 3  Batch: 27000  Loss: 3.182837463100441e-05\n",
            "Epoch: 3  Batch: 27600  Loss: 0.0009154658182524145\n",
            "Epoch: 3  Batch: 28200  Loss: 0.0\n",
            "Epoch: 3  Batch: 28800  Loss: 0.0\n",
            "Epoch: 3  Batch: 29400  Loss: 0.0\n",
            "Epoch: 3  Batch: 30000  Loss: 8.344646857949556e-07\n",
            "Epoch: 3  Batch: 30600  Loss: 0.03003549762070179\n",
            "Epoch: 3  Batch: 31200  Loss: 0.0\n",
            "Epoch: 3  Batch: 31800  Loss: 0.0\n",
            "Epoch: 3  Batch: 32400  Loss: 0.0\n",
            "Epoch: 3  Batch: 33000  Loss: 0.0013188959565013647\n",
            "Epoch: 3  Batch: 33600  Loss: 0.006042071618139744\n",
            "Epoch: 3  Batch: 34200  Loss: 0.00040260792593471706\n",
            "Epoch: 3  Batch: 34800  Loss: 3.576278118089249e-07\n",
            "Epoch: 3  Batch: 35400  Loss: 1.1324817933200393e-05\n",
            "Epoch: 3  Batch: 36000  Loss: 1.1920928244535389e-07\n",
            "Epoch: 3  Batch: 36600  Loss: 2.753696753643453e-05\n",
            "Epoch: 3  Batch: 37200  Loss: 0.0\n",
            "Epoch: 3  Batch: 37800  Loss: 0.0\n",
            "Epoch: 3  Batch: 38400  Loss: 1.1920928244535389e-07\n",
            "Epoch: 3  Batch: 39000  Loss: 0.0\n",
            "Epoch: 3  Batch: 39600  Loss: 0.0002644904307089746\n",
            "Epoch: 3  Batch: 40200  Loss: 0.0\n",
            "Epoch: 3  Batch: 40800  Loss: 1.1920928244535389e-07\n",
            "Epoch: 3  Batch: 41400  Loss: 5.960462772236497e-07\n",
            "Epoch: 3  Batch: 42000  Loss: 4.768370445162873e-07\n",
            "Epoch: 3  Batch: 42600  Loss: 4.1960789531003684e-05\n",
            "Epoch: 3  Batch: 43200  Loss: 3.2186455882765586e-06\n",
            "Epoch: 3  Batch: 43800  Loss: 0.5524640083312988\n",
            "Epoch: 3  Batch: 44400  Loss: 0.0\n",
            "Epoch: 3  Batch: 45000  Loss: 0.0004864939546678215\n",
            "Epoch: 3  Batch: 45600  Loss: 0.0006252956227399409\n",
            "Epoch: 3  Batch: 46200  Loss: 0.00839313305914402\n",
            "Epoch: 3  Batch: 46800  Loss: 0.0\n",
            "Epoch: 3  Batch: 47400  Loss: 0.0\n",
            "Epoch: 3  Batch: 48000  Loss: 0.010199567303061485\n",
            "Epoch: 3  Batch: 48600  Loss: 0.040027420967817307\n",
            "Epoch: 3  Batch: 49200  Loss: 0.0\n",
            "Epoch: 3  Batch: 49800  Loss: 1.1920922133867862e-06\n",
            "Epoch: 3  Batch: 50400  Loss: 0.05041798576712608\n",
            "Epoch: 3  Batch: 51000  Loss: 0.0\n",
            "Epoch: 3  Batch: 51600  Loss: 9.667406266089529e-05\n",
            "Epoch: 3  Batch: 52200  Loss: 3.576278118089249e-07\n",
            "Epoch: 3  Batch: 52800  Loss: 2.8490614567999728e-05\n",
            "Epoch: 3  Batch: 53400  Loss: 0.00041345154750160873\n",
            "Epoch: 3  Batch: 54000  Loss: 0.0\n",
            "Epoch: 3  Batch: 54600  Loss: 0.00040570611599832773\n",
            "Epoch: 3  Batch: 55200  Loss: 3.576278118089249e-07\n",
            "Epoch: 3  Batch: 55800  Loss: 9.536738616588991e-07\n",
            "Epoch: 3  Batch: 56400  Loss: 0.0\n",
            "Epoch: 3  Batch: 57000  Loss: 4.768370445162873e-07\n",
            "Epoch: 3  Batch: 57600  Loss: 0.0005814530304633081\n",
            "Epoch: 3  Batch: 58200  Loss: 0.0\n",
            "Epoch: 3  Batch: 58800  Loss: 0.004376476630568504\n",
            "Epoch: 3  Batch: 59400  Loss: 2.3841855067985307e-07\n",
            "Epoch: 3  Batch: 60000  Loss: 0.00026008085114881396\n",
            "Epoch: 4  Batch: 600  Loss: 3.516612196108326e-05\n",
            "Epoch: 4  Batch: 1200  Loss: 0.0\n",
            "Epoch: 4  Batch: 1800  Loss: 0.09657854586839676\n",
            "Epoch: 4  Batch: 2400  Loss: 3.2305197237292305e-05\n",
            "Epoch: 4  Batch: 3000  Loss: 1.1920928244535389e-07\n",
            "Epoch: 4  Batch: 3600  Loss: 0.003960860893130302\n",
            "Epoch: 4  Batch: 4200  Loss: 0.14130941033363342\n",
            "Epoch: 4  Batch: 4800  Loss: 0.0\n",
            "Epoch: 4  Batch: 5400  Loss: 0.00013422065239865333\n",
            "Epoch: 4  Batch: 6000  Loss: 5.960462772236497e-07\n",
            "Epoch: 4  Batch: 6600  Loss: 7.152555099310121e-07\n",
            "Epoch: 4  Batch: 7200  Loss: 2.3841855067985307e-07\n",
            "Epoch: 4  Batch: 7800  Loss: 0.0\n",
            "Epoch: 4  Batch: 8400  Loss: 0.0\n",
            "Epoch: 4  Batch: 9000  Loss: 0.0\n",
            "Epoch: 4  Batch: 9600  Loss: 0.0\n",
            "Epoch: 4  Batch: 10200  Loss: 0.002997669158503413\n",
            "Epoch: 4  Batch: 10800  Loss: 0.0\n",
            "Epoch: 4  Batch: 11400  Loss: 0.0\n",
            "Epoch: 4  Batch: 12000  Loss: 0.0\n",
            "Epoch: 4  Batch: 12600  Loss: 0.0\n",
            "Epoch: 4  Batch: 13200  Loss: 0.0\n",
            "Epoch: 4  Batch: 13800  Loss: 9.011816291604191e-05\n",
            "Epoch: 4  Batch: 14400  Loss: 0.0\n",
            "Epoch: 4  Batch: 15000  Loss: 0.0\n",
            "Epoch: 4  Batch: 15600  Loss: 2.5152843591058627e-05\n",
            "Epoch: 4  Batch: 16200  Loss: 0.0\n",
            "Epoch: 4  Batch: 16800  Loss: 0.0\n",
            "Epoch: 4  Batch: 17400  Loss: 0.0\n",
            "Epoch: 4  Batch: 18000  Loss: 0.0\n",
            "Epoch: 4  Batch: 18600  Loss: 0.0\n",
            "Epoch: 4  Batch: 19200  Loss: 0.0\n",
            "Epoch: 4  Batch: 19800  Loss: 0.0\n",
            "Epoch: 4  Batch: 20400  Loss: 0.0\n",
            "Epoch: 4  Batch: 21000  Loss: 0.00018285033002030104\n",
            "Epoch: 4  Batch: 21600  Loss: 0.0\n",
            "Epoch: 4  Batch: 22200  Loss: 4.541770613286644e-05\n",
            "Epoch: 4  Batch: 22800  Loss: 0.0\n",
            "Epoch: 4  Batch: 23400  Loss: 2.50339189733495e-06\n",
            "Epoch: 4  Batch: 24000  Loss: 4.029192859889008e-05\n",
            "Epoch: 4  Batch: 24600  Loss: 0.0005265279905870557\n",
            "Epoch: 4  Batch: 25200  Loss: 0.0019921474158763885\n",
            "Epoch: 4  Batch: 25800  Loss: 4.005352093372494e-05\n",
            "Epoch: 4  Batch: 26400  Loss: 0.0\n",
            "Epoch: 4  Batch: 27000  Loss: 0.0006986799417063594\n",
            "Epoch: 4  Batch: 27600  Loss: 0.0703222006559372\n",
            "Epoch: 4  Batch: 28200  Loss: 0.02983858808875084\n",
            "Epoch: 4  Batch: 28800  Loss: 0.0\n",
            "Epoch: 4  Batch: 29400  Loss: 2.145764938177308e-06\n",
            "Epoch: 4  Batch: 30000  Loss: 1.4305104514278355e-06\n",
            "Epoch: 4  Batch: 30600  Loss: 0.0\n",
            "Epoch: 4  Batch: 31200  Loss: 0.0\n",
            "Epoch: 4  Batch: 31800  Loss: 4.8874615458771586e-05\n",
            "Epoch: 4  Batch: 32400  Loss: 0.0\n",
            "Epoch: 4  Batch: 33000  Loss: 0.0022991669829934835\n",
            "Epoch: 4  Batch: 33600  Loss: 3.576272320060525e-06\n",
            "Epoch: 4  Batch: 34200  Loss: 1.1920928244535389e-07\n",
            "Epoch: 4  Batch: 34800  Loss: 4.768370445162873e-07\n",
            "Epoch: 4  Batch: 35400  Loss: 0.0\n",
            "Epoch: 4  Batch: 36000  Loss: 1.5616295058862306e-05\n",
            "Epoch: 4  Batch: 36600  Loss: 1.0779528617858887\n",
            "Epoch: 4  Batch: 37200  Loss: 3.886147169396281e-05\n",
            "Epoch: 4  Batch: 37800  Loss: 2.264974000354414e-06\n",
            "Epoch: 4  Batch: 38400  Loss: 1.0371154530730564e-05\n",
            "Epoch: 4  Batch: 39000  Loss: 0.013388960622251034\n",
            "Epoch: 4  Batch: 39600  Loss: 0.009349845349788666\n",
            "Epoch: 4  Batch: 40200  Loss: 8.344646857949556e-07\n",
            "Epoch: 4  Batch: 40800  Loss: 0.0\n",
            "Epoch: 4  Batch: 41400  Loss: 1.1920928244535389e-07\n",
            "Epoch: 4  Batch: 42000  Loss: 0.0\n",
            "Epoch: 4  Batch: 42600  Loss: 2.3841855067985307e-07\n",
            "Epoch: 4  Batch: 43200  Loss: 4.768370445162873e-07\n",
            "Epoch: 4  Batch: 43800  Loss: 0.0\n",
            "Epoch: 4  Batch: 44400  Loss: 0.0\n",
            "Epoch: 4  Batch: 45000  Loss: 4.410646579344757e-05\n",
            "Epoch: 4  Batch: 45600  Loss: 1.1920928244535389e-07\n",
            "Epoch: 4  Batch: 46200  Loss: 0.39465203881263733\n",
            "Epoch: 4  Batch: 46800  Loss: 0.0\n",
            "Epoch: 4  Batch: 47400  Loss: 6.615896563744172e-05\n",
            "Epoch: 4  Batch: 48000  Loss: 0.0\n",
            "Epoch: 4  Batch: 48600  Loss: 6.747018051100895e-05\n",
            "Epoch: 4  Batch: 49200  Loss: 0.0\n",
            "Epoch: 4  Batch: 49800  Loss: 0.0\n",
            "Epoch: 4  Batch: 50400  Loss: 0.0\n",
            "Epoch: 4  Batch: 51000  Loss: 0.022157490253448486\n",
            "Epoch: 4  Batch: 51600  Loss: 3.182837463100441e-05\n",
            "Epoch: 4  Batch: 52200  Loss: 0.0\n",
            "Epoch: 4  Batch: 52800  Loss: 0.01246695313602686\n",
            "Epoch: 4  Batch: 53400  Loss: 0.0\n",
            "Epoch: 4  Batch: 54000  Loss: 0.0\n",
            "Epoch: 4  Batch: 54600  Loss: 0.0\n",
            "Epoch: 4  Batch: 55200  Loss: 9.298280929215252e-06\n",
            "Epoch: 4  Batch: 55800  Loss: 0.00011848701251437888\n",
            "Epoch: 4  Batch: 56400  Loss: 1.156323378381785e-05\n",
            "Epoch: 4  Batch: 57000  Loss: 0.0\n",
            "Epoch: 4  Batch: 57600  Loss: 0.0\n",
            "Epoch: 4  Batch: 58200  Loss: 5.960462772236497e-07\n",
            "Epoch: 4  Batch: 58800  Loss: 0.0\n",
            "Epoch: 4  Batch: 59400  Loss: 3.4570634852570947e-06\n",
            "Epoch: 4  Batch: 60000  Loss: 1.811964830267243e-05\n",
            "Training Took: 1548.9644644260406/60 minutes!\n"
          ]
        }
      ]
    }
  ]
}